<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>visageSDK: VisageTracker2.h Source File</title>

<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />



</head>
<body>
<div id="top"><!-- do not remove this div! -->


<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  
  
  <td style="padding-left: 0.5em;">
   <div id="projectname">visageSDK
   
   </div>
   
  </td>
  
  
  
 </tr>
 </tbody>
</table>
</div>

<!-- Generated by Doxygen 1.7.6.1 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<div class="title">VisageTracker2.h</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 
<a name="l00002"></a>00002 <span class="preprocessor">#ifndef __VisageTracker2_h__</span>
<a name="l00003"></a>00003 <span class="preprocessor"></span><span class="preprocessor">#define __VisageTracker2_h__</span>
<a name="l00004"></a>00004 <span class="preprocessor"></span>
<a name="l00005"></a>00005 <span class="preprocessor">#ifdef VISAGE_STATIC</span>
<a name="l00006"></a>00006 <span class="preprocessor"></span><span class="preprocessor">        #define VISAGE_DECLSPEC</span>
<a name="l00007"></a>00007 <span class="preprocessor"></span><span class="preprocessor">#else</span>
<a name="l00008"></a>00008 <span class="preprocessor"></span>
<a name="l00009"></a>00009 <span class="preprocessor">        #ifdef VISAGE_EXPORTS</span>
<a name="l00010"></a>00010 <span class="preprocessor"></span><span class="preprocessor">                #define VISAGE_DECLSPEC __declspec(dllexport)</span>
<a name="l00011"></a>00011 <span class="preprocessor"></span><span class="preprocessor">        #else</span>
<a name="l00012"></a>00012 <span class="preprocessor"></span><span class="preprocessor">                #define VISAGE_DECLSPEC __declspec(dllimport)</span>
<a name="l00013"></a>00013 <span class="preprocessor"></span><span class="preprocessor">        #endif</span>
<a name="l00014"></a>00014 <span class="preprocessor"></span>
<a name="l00015"></a>00015 <span class="preprocessor">#endif</span>
<a name="l00016"></a>00016 <span class="preprocessor"></span>
<a name="l00017"></a>00017 
<a name="l00018"></a>00018 <span class="preprocessor">#include &lt;cstdlib&gt;</span>
<a name="l00019"></a>00019 <span class="preprocessor">#include &quot;FbaAction.h&quot;</span>
<a name="l00020"></a>00020 <span class="preprocessor">#include &quot;FAPs.h&quot;</span>
<a name="l00021"></a>00021 <span class="preprocessor">#include &quot;FBFT/FBFT.h&quot;</span>
<a name="l00022"></a>00022 
<a name="l00023"></a>00023 <span class="preprocessor">#include &quot;TrackerOpenGLInterface.h&quot;</span>
<a name="l00024"></a>00024 <span class="preprocessor">#include &quot;TrackerGUIInterface.h&quot;</span>
<a name="l00025"></a>00025 <span class="preprocessor">#include &quot;TrackerInternalInterface.h&quot;</span>
<a name="l00026"></a>00026 <span class="preprocessor">#include &quot;SmoothingFilter.h&quot;</span>
<a name="l00027"></a>00027 <span class="preprocessor">#include &quot;VisageTrackerObserver.h&quot;</span>
<a name="l00028"></a>00028 <span class="comment">//#include &quot;VisageFeaturesDetector.h&quot;</span>
<a name="l00029"></a>00029 <span class="preprocessor">#include &quot;VisageTrackerFrameGrabber.h&quot;</span>
<a name="l00030"></a>00030 <span class="preprocessor">#include &quot;TrackingData.h&quot;</span>
<a name="l00031"></a>00031 <span class="preprocessor">#include &quot;VisageDetector.h&quot;</span>
<a name="l00032"></a>00032 
<a name="l00033"></a>00033 <span class="keyword">using namespace </span>std;
<a name="l00034"></a>00034 <span class="preprocessor">#ifdef WIN32</span>
<a name="l00035"></a>00035 <span class="preprocessor"></span><span class="keyword">class </span>videoInput;
<a name="l00036"></a>00036 <span class="preprocessor">#endif</span>
<a name="l00037"></a>00037 <span class="preprocessor"></span><span class="preprocessor">#ifdef IOS</span>
<a name="l00038"></a>00038 <span class="preprocessor"></span><span class="keyword">namespace </span>VisageSDK
<a name="l00039"></a>00039 {
<a name="l00040"></a>00040 <span class="keyword">class </span>iOSCapture;
<a name="l00041"></a>00041 }
<a name="l00042"></a>00042 <span class="preprocessor">#endif</span>
<a name="l00043"></a>00043 <span class="preprocessor"></span>
<a name="l00044"></a>00044 <span class="preprocessor">#ifdef MAC_OS_X</span>
<a name="l00045"></a>00045 <span class="preprocessor"></span><span class="keyword">namespace </span>VisageSDK
<a name="l00046"></a>00046 {
<a name="l00047"></a>00047     <span class="keyword">class </span>OSXCapture;
<a name="l00048"></a>00048 }
<a name="l00049"></a>00049 <span class="preprocessor">#endif</span>
<a name="l00050"></a>00050 <span class="preprocessor"></span>
<a name="l00051"></a>00051 <span class="preprocessor">#ifdef ANDROID</span>
<a name="l00052"></a>00052 <span class="preprocessor"></span><span class="keyword">extern</span> <span class="stringliteral">&quot;C&quot;</span> {
<a name="l00053"></a>00053         VISAGE_DECLSPEC <span class="keywordtype">void</span> _loadVisageVision();
<a name="l00054"></a>00054 }
<a name="l00055"></a>00055 <span class="preprocessor">#endif</span>
<a name="l00056"></a>00056 <span class="preprocessor"></span>
<a name="l00057"></a>00057 <span class="preprocessor">#ifndef WIN32</span>
<a name="l00058"></a>00058 <span class="preprocessor"></span><span class="preprocessor">#include &lt;pthread.h&gt;</span>
<a name="l00059"></a>00059 <span class="preprocessor">#include &lt;sys/types.h&gt;</span>
<a name="l00060"></a>00060 <span class="preprocessor">#define HANDLE pthread_t*</span>
<a name="l00061"></a>00061 <span class="preprocessor"></span><span class="preprocessor">#endif</span>
<a name="l00062"></a>00062 <span class="preprocessor"></span>
<a name="l00063"></a>00063 
<a name="l00064"></a>00064 <span class="keyword">namespace </span>VisageSDK
<a name="l00065"></a>00065 {
<a name="l00066"></a>00066 
<a name="l00067"></a>00067 <span class="preprocessor">#define TRACK_STAT_OFF 0</span>
<a name="l00068"></a>00068 <span class="preprocessor"></span><span class="preprocessor">#define TRACK_STAT_OK 1</span>
<a name="l00069"></a>00069 <span class="preprocessor"></span><span class="preprocessor">#define TRACK_STAT_RECOVERING 2</span>
<a name="l00070"></a>00070 <span class="preprocessor"></span><span class="preprocessor">#define TRACK_STAT_INIT 3</span>
<a name="l00071"></a>00071 <span class="preprocessor"></span>
<a name="l00072"></a>00072 <span class="preprocessor">#define VISAGE_CAMERA_UP 0</span>
<a name="l00073"></a>00073 <span class="preprocessor"></span><span class="preprocessor">#define VISAGE_CAMERA_DOWN 1</span>
<a name="l00074"></a>00074 <span class="preprocessor"></span><span class="preprocessor">#define VISAGE_CAMERA_LEFT 2</span>
<a name="l00075"></a>00075 <span class="preprocessor"></span><span class="preprocessor">#define VISAGE_CAMERA_RIGHT 3</span>
<a name="l00076"></a>00076 <span class="preprocessor"></span>
<a name="l00077"></a>00077 <span class="keyword">class </span>ModelFitter;
<a name="l00078"></a>00078 
<a name="l00181"></a><a class="code" href="classVisageSDK_1_1VisageTracker2.html">00181</a> <span class="keyword">class </span>VISAGE_DECLSPEC <a class="code" href="classVisageSDK_1_1VisageTracker2.html" title="VisageTracker2 is a head/facial features tracker capable of tracking facial features in video coming ...">VisageTracker2</a> : <span class="keyword">public</span> FbaAction
<a name="l00182"></a>00182 {
<a name="l00183"></a>00183 <span class="keyword">public</span>:
<a name="l00184"></a>00184 
<a name="l00191"></a>00191         <a class="code" href="classVisageSDK_1_1VisageTracker2.html" title="VisageTracker2 is a head/facial features tracker capable of tracking facial features in video coming ...">VisageTracker2</a>(<span class="keyword">const</span> <span class="keywordtype">char</span>* trackerConfigFile);
<a name="l00192"></a>00192 
<a name="l00203"></a>00203         <a class="code" href="classVisageSDK_1_1VisageTracker2.html" title="VisageTracker2 is a head/facial features tracker capable of tracking facial features in video coming ...">VisageTracker2</a>(<a class="code" href="classVisageSDK_1_1TrackerOpenGLInterface.html" title="Optional OpenGL Interface for VisageTracker2.">TrackerOpenGLInterface</a> *oglInterface, <a class="code" href="classVisageSDK_1_1TrackerGUIInterface.html" title="Optional GUI Interface for VisageTracker2.">TrackerGUIInterface</a> *guiInterface, <span class="keyword">const</span> <span class="keywordtype">char</span>* trackerConfigFile);
<a name="l00204"></a>00204 
<a name="l00207"></a>00207         ~<a class="code" href="classVisageSDK_1_1VisageTracker2.html" title="VisageTracker2 is a head/facial features tracker capable of tracking facial features in video coming ...">VisageTracker2</a>();
<a name="l00208"></a>00208 
<a name="l00253"></a>00253         <span class="keywordtype">bool</span> trackFromCam(<span class="keyword">const</span> <span class="keywordtype">char</span>* outFbaFileName = NULL, <span class="keywordtype">int</span> orientation = VISAGE_CAMERA_UP, <span class="keywordtype">int</span> frameGrabberImageFormat = VISAGE_FRAMEGRABBER_FMT_RGB);
<a name="l00254"></a>00254         
<a name="l00255"></a>00255 
<a name="l00299"></a>00299         <span class="keywordtype">bool</span> trackFromVideo(<span class="keyword">const</span> <span class="keywordtype">char</span>* inVideoFileName,
<a name="l00300"></a>00300                                           <span class="keyword">const</span> <span class="keywordtype">char</span>* outFbaFileName = NULL);
<a name="l00301"></a>00301         <span class="comment">/* DEPRECATED, replaced by trackFromVideo().</span>
<a name="l00302"></a>00302 <span class="comment">        */</span>
<a name="l00303"></a>00303         <span class="keywordtype">bool</span> trackFromAvi(<span class="keyword">const</span> <span class="keywordtype">char</span>* inAviFileName,
<a name="l00304"></a>00304                                           <span class="keyword">const</span> <span class="keywordtype">char</span>* outFbaFileName = NULL);
<a name="l00359"></a>00359         <span class="keywordtype">bool</span> trackFromRawImages(<a class="code" href="classVisageSDK_1_1VisageTrackerFrameGrabber.html" title="VisageTrackerFrameGrabber interface.">VisageTrackerFrameGrabber</a> *frameGrabber,
<a name="l00360"></a>00360                                                         <span class="keywordtype">int</span> width, <span class="keywordtype">int</span> height, <span class="keywordtype">int</span> format, <span class="keywordtype">int</span> origin,
<a name="l00361"></a>00361                                                         <span class="keyword">const</span> <span class="keywordtype">char</span>* outFbaFileName = NULL);
<a name="l00362"></a>00362 
<a name="l00374"></a>00374         <span class="keywordtype">int</span> getTrackingData(<a class="code" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results.">FaceData</a> *data);
<a name="l00375"></a>00375         
<a name="l00376"></a>00376         <span class="comment">/*</span>
<a name="l00377"></a>00377 <span class="comment">        * This method fills the gven face data structure and returns the tracking status.</span>
<a name="l00378"></a>00378 <span class="comment">        *</span>
<a name="l00379"></a>00379 <span class="comment">        * On first call of this function the memory for the required member variables of the passed object will be allocated and initialized automatically.</span>
<a name="l00380"></a>00380 <span class="comment">        *</span>
<a name="l00381"></a>00381 <span class="comment">        * @param Face data structure that will be filled with current tracking data</span>
<a name="l00382"></a>00382 <span class="comment">        * @return tracking status (TRACK_STAT_OFF, TRACK_STAT_OK, TRACK_STAT_RECOVERING and TRACK_STAT_INIT, see @ref TrackingData for more details)</span>
<a name="l00383"></a>00383 <span class="comment">        *</span>
<a name="l00384"></a>00384 <span class="comment">        */</span>
<a name="l00385"></a>00385         <span class="keywordtype">int</span> getFaceData(<a class="code" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results.">FaceData</a> *data);
<a name="l00386"></a>00386 
<a name="l00394"></a>00394         <span class="keywordtype">void</span> setTrackerConfigurationFile(<span class="keywordtype">char</span>* trackerConfigFile);
<a name="l00395"></a>00395 
<a name="l00396"></a>00396         <span class="comment">/* Is tracker active?</span>
<a name="l00397"></a>00397 <span class="comment">        * This function is deprecated; please use @ref getTrackingStatus().</span>
<a name="l00398"></a>00398 <span class="comment">        *</span>
<a name="l00399"></a>00399 <span class="comment">        * Checks whether the tracker is currently active.</span>
<a name="l00400"></a>00400 <span class="comment">        * @return true if tracker is currently active, false otherwise.</span>
<a name="l00401"></a>00401 <span class="comment">        */</span>
<a name="l00402"></a>00402         <span class="keywordtype">bool</span> isActive() {<span class="keywordflow">return</span> this-&gt;active;};
<a name="l00403"></a>00403 
<a name="l00404"></a>00404         <span class="comment">/* Is tracker correctly tracking the face?</span>
<a name="l00405"></a>00405 <span class="comment">        * This function is deprecated; please use @ref getTrackingStatus().</span>
<a name="l00406"></a>00406 <span class="comment">        *</span>
<a name="l00407"></a>00407 <span class="comment">        * Checks whether the tracker is currently tracking the face.</span>
<a name="l00408"></a>00408 <span class="comment">        * @return true if tracker is currently tracking the face correctly, false if the tracker can currently not detect the face.</span>
<a name="l00409"></a>00409 <span class="comment">        */</span>
<a name="l00410"></a>00410         <span class="keywordtype">bool</span> isTrackingOK() {<span class="keywordflow">return</span> this-&gt;tracking_ok;};
<a name="l00411"></a>00411 
<a name="l00417"></a><a class="code" href="classVisageSDK_1_1VisageTracker2.html#abd95ebff358b73527a107e9c81c2cb5f">00417</a>         <span class="keywordtype">void</span> <a class="code" href="classVisageSDK_1_1VisageTracker2.html#abd95ebff358b73527a107e9c81c2cb5f" title="Attaches an observer implementation to the tracker.">attach</a>(<a class="code" href="classVisageSDK_1_1VisageTrackerObserver.html" title="VisageTrackerObserver interface.">VisageTrackerObserver</a> * _obs) {obs[nObs++] = _obs;};
<a name="l00418"></a>00418 
<a name="l00419"></a>00419 
<a name="l00426"></a><a class="code" href="classVisageSDK_1_1VisageTracker2.html#a8af56d31d87e706df6fa45bc702a03d6">00426</a>         <span class="keywordtype">void</span> <a class="code" href="classVisageSDK_1_1VisageTracker2.html#a8af56d31d87e706df6fa45bc702a03d6" title="Detaches all attached observers from the tracker.">detach</a>() {nObs = 0;};
<a name="l00427"></a>00427 
<a name="l00436"></a>00436         <span class="keywordtype">bool</span> showCameraSettingsDialog();
<a name="l00437"></a>00437 
<a name="l00438"></a>00438 
<a name="l00467"></a>00467         FBAPs *getFBAPs(<span class="keywordtype">long</span> globalTime, FBAPs *lastFBAPs, VisageCharModel* model);
<a name="l00468"></a>00468 
<a name="l00469"></a>00469 
<a name="l00470"></a>00470         <span class="comment">/* Get facial feature points estimated by the tracker.</span>
<a name="l00471"></a>00471 <span class="comment">        *</span>
<a name="l00472"></a>00472 <span class="comment">        * The feature points are identified</span>
<a name="l00473"></a>00473 <span class="comment">        * according to the MPEG-4 standard, so each feature point is identified by its group and index. For example, the tip of the chin</span>
<a name="l00474"></a>00474 <span class="comment">        * belongs to group 2 and its index is 1, so this point is identified as point 2.1. The identification of all MPEG-4 feature points is</span>
<a name="l00475"></a>00475 <span class="comment">        * illustrated in Figure 2 on Page 8 of the &lt;a href=&quot;../MPEG-4 FBA Overview.pdf&quot;&gt;MPEG-4 Face and Body Animation Introduction&lt;/a&gt;.</span>
<a name="l00476"></a>00476 <span class="comment">        *</span>
<a name="l00477"></a>00477 <span class="comment">        * Certain feature points, like the ones on the tongue and teeth, can not be reliably detected so they are not returned</span>
<a name="l00478"></a>00478 <span class="comment">        * and their coordinates are always set to zero. These points are:</span>
<a name="l00479"></a>00479 <span class="comment">        * 3.5, 3.6, 6.1, 6.2, 6.3, 6.4, 7.1, 9.8, 9.9, 9.10, 9.11, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 11.4, 11.5, 11.6</span>
<a name="l00480"></a>00480 <span class="comment">        * Several other points are estimated, rather than accurately detected, due to their specific locations. Examples of such points</span>
<a name="l00481"></a>00481 <span class="comment">        * are 11.4 (usually hidden in the hair), hairline points (10.1 - 10.3) as well as cheeck points 5.1 - 5.4 which can not be precisely defined due to lack of</span>
<a name="l00482"></a>00482 <span class="comment">        * features on the cheek.</span>
<a name="l00483"></a>00483 <span class="comment">        *</span>
<a name="l00484"></a>00484 <span class="comment">        * The resulting feature point coordinates are returned in form of an FDP object. This is a container clas used for storage of MPEG-4 feature points.</span>
<a name="l00485"></a>00485 <span class="comment">        * It provides functions to access each feature point by its group and index and to read its coordinates. Note that FDP can store 3D points but</span>
<a name="l00486"></a>00486 <span class="comment">        * in case of 2D return feature points only the x and y coordinates of each point are used.</span>
<a name="l00487"></a>00487 <span class="comment">        *</span>
<a name="l00488"></a>00488 <span class="comment">        * In case of absolute 3D coordinates (relative = false), the coordinate system is such that when looking towards the video image, the direction of x is to the</span>
<a name="l00489"></a>00489 <span class="comment">        * left, y iz up, and z points into the image, away from the viewer. The global origin (0,0,0) is placed at the camera.</span>
<a name="l00490"></a>00490 <span class="comment">        *</span>
<a name="l00491"></a>00491 <span class="comment">        * In case of relative 3D coordinates (relative = true), the coordinate system is such that when looking towards the video image, the direction of x is to the</span>
<a name="l00492"></a>00492 <span class="comment">        * right, y iz up, and z points out of the image, towards the viewer. The  origin (0,0,0) is placed at the left eye of the person (i.e. the eye that is on the right in the image).</span>
<a name="l00493"></a>00493 <span class="comment">        *</span>
<a name="l00494"></a>00494 <span class="comment">        * The 2D coordinates are normalised to image size so that the lower left corner of the image has coordinates 0,0 and upper right corner 1,1.</span>
<a name="l00495"></a>00495 <span class="comment">        *</span>
<a name="l00496"></a>00496 <span class="comment">        * @param initial if true, function returns the feature points from the initial frame of video, otherwise it returns the latest estimated points.</span>
<a name="l00497"></a>00497 <span class="comment">        * @param relative if true, function returns the coordinates relative to the head (i.e. coordinates in the coordinate system of the head), otherwise it returns global coordinates. this parameter is ignored if 2D coordinates are requested.</span>
<a name="l00498"></a>00498 <span class="comment">        * @param _3D if true, the function returns 3D coordinates of feature points. Otherwise, it returns 2D coordinates normalised to image size so that the upper left corner of the image has coordinates 0,0 and lower right corner 1,1.</span>
<a name="l00499"></a>00499 <span class="comment">        */</span>
<a name="l00500"></a>00500         <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *getFeaturePoints(<span class="keywordtype">bool</span> initial, <span class="keywordtype">bool</span> relative, <span class="keywordtype">bool</span> _3D);
<a name="l00501"></a>00501 
<a name="l00502"></a>00502         <span class="comment">/* Draw the tracking results.</span>
<a name="l00503"></a>00503 <span class="comment">        *</span>
<a name="l00504"></a>00504 <span class="comment">        * Visualize the most recent tracking results in the current OpenGL window.</span>
<a name="l00505"></a>00505 <span class="comment">        *</span>
<a name="l00506"></a>00506 <span class="comment">        */</span>
<a name="l00507"></a>00507         <span class="keywordtype">void</span> drawResults();
<a name="l00508"></a>00508 
<a name="l00509"></a>00509         <span class="comment">//helper functions for drawResults()</span>
<a name="l00510"></a>00510         <span class="keywordtype">void</span> drawPoint(<span class="keywordtype">int</span> i,<span class="keywordtype">int</span> j);
<a name="l00511"></a>00511         <span class="keywordtype">void</span> drawPoint3D(<span class="keywordtype">int</span> i,<span class="keywordtype">int</span> j);
<a name="l00512"></a>00512         <span class="keywordtype">void</span> drawPoints2D(<span class="keywordtype">int</span> *points, <span class="keywordtype">int</span> num, <span class="keywordtype">int</span> drawType);
<a name="l00513"></a>00513         <span class="keywordtype">void</span> drawPoints3D(<span class="keywordtype">int</span> *points, <span class="keywordtype">int</span> num, <span class="keywordtype">int</span> drawType);
<a name="l00514"></a>00514 
<a name="l00515"></a>00515         <span class="comment">/* Get the current frame rate.</span>
<a name="l00516"></a>00516 <span class="comment">        *</span>
<a name="l00517"></a>00517 <span class="comment">        * This function returns the frame rate of the tracker, in frames per second,</span>
<a name="l00518"></a>00518 <span class="comment">        * measured ovber last 10 frames.</span>
<a name="l00519"></a>00519 <span class="comment">        *</span>
<a name="l00520"></a>00520 <span class="comment">        * @return The measured tracking frame rate, in frames per second.</span>
<a name="l00521"></a>00521 <span class="comment">        */</span>
<a name="l00522"></a>00522         <span class="keywordtype">float</span> getFrameRate() {<span class="keywordflow">if</span>(active) <span class="keywordflow">return</span> trackingFrameRate; <span class="keywordflow">else</span> <span class="keywordflow">return</span> 0.0f;};
<a name="l00523"></a>00523 
<a name="l00524"></a>00524         <span class="comment">/* Get the current tracking status.</span>
<a name="l00525"></a>00525 <span class="comment">        *</span>
<a name="l00526"></a>00526 <span class="comment">        * Returns the current status of the tracker, which can be one of the following:</span>
<a name="l00527"></a>00527 <span class="comment">        *</span>
<a name="l00528"></a>00528 <span class="comment">        * &lt;table&gt;</span>
<a name="l00529"></a>00529 <span class="comment">        * &lt;tr&gt;&lt;td width=&quot;100&quot;&gt;&lt;b&gt;RETURN VALUE&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;DESCRIPTION&lt;/b&gt;&lt;/td&gt;&lt;/tr&gt;</span>
<a name="l00530"></a>00530 <span class="comment">        * &lt;tr&gt;&lt;td&gt;TRACK_STAT_OFF&lt;/td&gt;&lt;td&gt;Tracker is not active, i.e. it has not yet been started, or it has been stopped.&lt;/td&gt;&lt;/tr&gt;</span>
<a name="l00531"></a>00531 <span class="comment">        * &lt;tr&gt;&lt;td&gt;TRACK_STAT_OK&lt;/td&gt;&lt;td&gt;Tracker is tracking normally.&lt;/td&gt;&lt;/tr&gt;</span>
<a name="l00532"></a>00532 <span class="comment">        * &lt;tr&gt;&lt;td&gt;TRACK_STAT_RECOVERING&lt;/td&gt;&lt;td&gt;Tracker has lost the face and is attempting to recover and continue tracking. If it can not recover within the time defined by the parameter recovery_timeout in the tracker configuration file, the tracker will fully re-initialize (i.e. it will assume that a new user may be present).&lt;/td&gt;&lt;/tr&gt;</span>
<a name="l00533"></a>00533 <span class="comment">        * &lt;tr&gt;&lt;td&gt;TRACK_STAT_INIT&lt;/td&gt;&lt;td&gt;Tracker is initializing. The tracker enters this state immediately when it is started, or when it has lost the face and failed to recover (see TRACK_STAT_RECOVERING above). The initialization process is configurable through a number of parameters in the tracker configuration file.&lt;/td&gt;&lt;/tr&gt;</span>
<a name="l00534"></a>00534 <span class="comment">        * &lt;/table&gt;</span>
<a name="l00535"></a>00535 <span class="comment">        *</span>
<a name="l00536"></a>00536 <span class="comment">        * When the status is TRACK_STAT_INIT, the method returns additional initialization status information through its arguments (for other states the arguments are neither used nor modified by the method).</span>
<a name="l00537"></a>00537 <span class="comment">        * The purpose of this is to display the initialization status on the screen in order to aid the user in positioning their face in the best pose for initialization.</span>
<a name="l00538"></a>00538 <span class="comment">        *</span>
<a name="l00539"></a>00539 <span class="comment">        * When the status is TRACK_STAT_OK, the method returns an additional tracking quality information through its track_quality argument (for other states the argument is neither used nor modified by the method).</span>
<a name="l00540"></a>00540 <span class="comment">        *</span>
<a name="l00541"></a>00541 <span class="comment">        * @param display_status Output argument; set only while tracker is initializing. It indicates whether the display of initialization status is enabled or disabled by the init_display_status parameter in the tracker configuration file. If it is true, initialization status should be displayed. This allows the display to be controlled from the configuration file.</span>
<a name="l00542"></a>00542 <span class="comment">        * @param face_detected Output argument; set only while tracker is initializing. It returns true if a face and its main features are currently detected, false otherwise. If this value is false, no values are set for yaw, roll and velocity.</span>
<a name="l00543"></a>00543 <span class="comment">        * @param yaw Output argument; set only while tracker is initializing. It returns a measure of head yaw (left-right rotation of the head). It is expressed in meters, as the deviation of the nose tip position from the imaginary line drawn between the eyes perpendicular to left eye - right eye connecting line. Positive values are to the user&#39;s right (i.e. to the left in the image).</span>
<a name="l00544"></a>00544 <span class="comment">        * @param roll Output argument; set only while tracker is initializing. It returns head roll (tilt of the head to left or right). It is expressed in degrees. Positive values are to the user&#39;s left (i.e. to the right in the image).</span>
<a name="l00545"></a>00545 <span class="comment">        * @param velocity Output argument; set only while tracker is initializing. It returns the estimated velocity of nose tip motion, in meters per second.</span>
<a name="l00546"></a>00546 <span class="comment">        * @param track_quality Output argument; set only while tracker is tracking (TRACK_STAT_OK). It returns the estimate of tracking quality level for the current frame. The value is between 0 and 1, and it corresponds to the global_bad_match_threshold parameter in the tracker configuration file, i.e. the quality measure is checked against this threshold and when it falls below the tracker resets itself.</span>
<a name="l00547"></a>00547 <span class="comment">        * @return The current status of the tracker, see table above.</span>
<a name="l00548"></a>00548 <span class="comment">        */</span>
<a name="l00549"></a>00549         <span class="keywordtype">int</span> getTrackingStatus(<span class="keywordtype">bool</span> &amp;display_status, <span class="keywordtype">bool</span> &amp;face_detected, <span class="keywordtype">float</span> &amp;yaw, <span class="keywordtype">float</span> &amp;roll, <span class="keywordtype">float</span> &amp;velocity, <span class="keywordtype">float</span> &amp;track_quality);
<a name="l00550"></a>00550 
<a name="l00551"></a>00551         <span class="comment">/* Get the tracker image resolution.</span>
<a name="l00552"></a>00552 <span class="comment">        *</span>
<a name="l00553"></a>00553 <span class="comment">        * This function returns the resolution of tracker input image, working image and display.</span>
<a name="l00554"></a>00554 <span class="comment">        * The input resolution is the resolution of the input video file or camera.</span>
<a name="l00555"></a>00555 <span class="comment">        * Depending on the configuration file, the tracker may reduce the input image to working resolution.</span>
<a name="l00556"></a>00556 <span class="comment">        * Finally, the display resolution is the resolution of the image presented in the application window; this resolution is also set in the configuration file.</span>
<a name="l00557"></a>00557 <span class="comment">        *</span>
<a name="l00558"></a>00558 <span class="comment">        * @param ix returns the horizontal input resolution.</span>
<a name="l00559"></a>00559 <span class="comment">        * @param iy returns the vertical input resolution.</span>
<a name="l00560"></a>00560 <span class="comment">        * @param wx returns the horizontal work resolution.</span>
<a name="l00561"></a>00561 <span class="comment">        * @param wy returns the vertical work resolution.</span>
<a name="l00562"></a>00562 <span class="comment">        * @param dx returns the horizontal display resolution.</span>
<a name="l00563"></a>00563 <span class="comment">        * @param dy returns the vertical display resolution.</span>
<a name="l00564"></a>00564 <span class="comment">        */</span>
<a name="l00565"></a>00565         <span class="keywordtype">void</span> getResolution(<span class="keywordtype">int</span> &amp;ix, <span class="keywordtype">int</span> &amp;iy, <span class="keywordtype">int</span> &amp;wx, <span class="keywordtype">int</span> &amp;wy, <span class="keywordtype">int</span> &amp;dx, <span class="keywordtype">int</span> &amp;dy);
<a name="l00566"></a>00566 
<a name="l00567"></a>00567         <span class="comment">/* Get the rotation of the face (head).</span>
<a name="l00568"></a>00568 <span class="comment">        *</span>
<a name="l00569"></a>00569 <span class="comment">        * This function returns the estimated rotation of the head, in radians.</span>
<a name="l00570"></a>00570 <span class="comment">        * It can return either the initial rotation (the rotation the first frame</span>
<a name="l00571"></a>00571 <span class="comment">        * of the video) or the current rotation.</span>
<a name="l00572"></a>00572 <span class="comment">        * Rotation is expressed with three values determining the rotations</span>
<a name="l00573"></a>00573 <span class="comment">        * around the three axes x, y and z, in radians. This means that the values represent</span>
<a name="l00574"></a>00574 <span class="comment">        * the pitch, yaw and roll of the head, respectively. The zero rotation</span>
<a name="l00575"></a>00575 <span class="comment">        * (values 0, 0, 0) corresponds to the face looking straight ahead.</span>
<a name="l00576"></a>00576 <span class="comment">        * Positive values for pitch correspond to head turning down.</span>
<a name="l00577"></a>00577 <span class="comment">        * Positive values for yaw correspond to head turning left (from its own perspective).</span>
<a name="l00578"></a>00578 <span class="comment">        * Positive values for roll correspond to head rolling to the right (from its own perspective).</span>
<a name="l00579"></a>00579 <span class="comment">        * The values are in radians.</span>
<a name="l00580"></a>00580 <span class="comment">        *</span>
<a name="l00581"></a>00581 <span class="comment">        * @param initial if true, the function returns initial rotation; otherwise it returns the current rotation.</span>
<a name="l00582"></a>00582 <span class="comment">        * @return pointer to the array with the rotation values around x, y and z axes (yaw, pitch and roll).</span>
<a name="l00583"></a>00583 <span class="comment">        */</span>
<a name="l00584"></a>00584         <span class="keywordtype">float</span> *getFaceRotation(<span class="keywordtype">bool</span> initial);
<a name="l00585"></a>00585 
<a name="l00586"></a>00586         <span class="comment">/* Get the translation of the face (head).</span>
<a name="l00587"></a>00587 <span class="comment">        *</span>
<a name="l00588"></a>00588 <span class="comment">        * This function returns the current estimated translation of the head,</span>
<a name="l00589"></a>00589 <span class="comment">        * either relative to its initial position in the first video frame or absolute (i.e. relative to the camera position).</span>
<a name="l00590"></a>00590 <span class="comment">        * A typical application using relative translation is character animation, while absolute translation is usefull for example in AR type of applications.</span>
<a name="l00591"></a>00591 <span class="comment">        *</span>
<a name="l00592"></a>00592 <span class="comment">        * Translation is expressed with three coordinates x, y, z.</span>
<a name="l00593"></a>00593 <span class="comment">        * When looking towards the video image, the direction of x is to the</span>
<a name="l00594"></a>00594 <span class="comment">        * left, y iz up, and z points forward into the image.</span>
<a name="l00595"></a>00595 <span class="comment">        *</span>
<a name="l00596"></a>00596 <span class="comment">        * If relative is TRUE, the function returns the translation of the head relative to its</span>
<a name="l00597"></a>00597 <span class="comment">        * position in the first video frame. The coordinates are normalised with respect to the eye separation</span>
<a name="l00598"></a>00598 <span class="comment">        * distance of the tracked face. This means that the value of 1</span>
<a name="l00599"></a>00599 <span class="comment">        * corresponds to the translation equal to the distance between the</span>
<a name="l00600"></a>00600 <span class="comment">        * person&#39;s eyes.</span>
<a name="l00601"></a>00601 <span class="comment">        *</span>
<a name="l00602"></a>00602 <span class="comment">        * If relative is TRUE, the function can return compensated or uncompensated</span>
<a name="l00603"></a>00603 <span class="comment">        * translation depending on the value of the parameter compensated.</span>
<a name="l00604"></a>00604 <span class="comment">        * Uncompensated translation is the raw translation estimated by the tracker.</span>
<a name="l00605"></a>00605 <span class="comment">        * Compensated translation values take into account the fact that the tracker</span>
<a name="l00606"></a>00606 <span class="comment">        * uses a relatively flat face model for tracking, so the center of rotation of this model</span>
<a name="l00607"></a>00607 <span class="comment">        * is in the front area of the head, while the anatomical center</span>
<a name="l00608"></a>00608 <span class="comment">        * of rotation is behind, in the base of the neck. Therefore, when the rotation</span>
<a name="l00609"></a>00609 <span class="comment">        * is applied to a 3D head model with anatomically correct center of rotation, the</span>
<a name="l00610"></a>00610 <span class="comment">        * face naturally translates as well. When this translation is compounded with</span>
<a name="l00611"></a>00611 <span class="comment">        * the translation values obtained from the tracker, the total resulting translation</span>
<a name="l00612"></a>00612 <span class="comment">        * is exaggerated. To avoid this exaggerated translation of the animated head,</span>
<a name="l00613"></a>00613 <span class="comment">        * the translation can be compensated. The compensation algorithm</span>
<a name="l00614"></a>00614 <span class="comment">        * estimates how much the translation would be exaggerated, and makes it that much</span>
<a name="l00615"></a>00615 <span class="comment">        * smaller. The compensated translation can directly be applied to animated head</span>
<a name="l00616"></a>00616 <span class="comment">        * models that use the neck base as the center of rotation, and is expected to give</span>
<a name="l00617"></a>00617 <span class="comment">        * better results than the uncompensated translation. The compensation can be fine-tuned</span>
<a name="l00618"></a>00618 <span class="comment">        * using the @ref translation_compensation_factor attribute.</span>
<a name="l00619"></a>00619 <span class="comment">        *</span>
<a name="l00620"></a>00620 <span class="comment">        * If relative is FALSE, the function returns the position of the head</span>
<a name="l00621"></a>00621 <span class="comment">        * relative to the camera, i.e. the absolute head position in the camera space. The parameter &quot;compensated&quot;</span>
<a name="l00622"></a>00622 <span class="comment">        * is ignored.</span>
<a name="l00623"></a>00623 <span class="comment">        * If the value set for the camera</span>
<a name="l00624"></a>00624 <span class="comment">        * focal length in the &lt;a href=&quot;doc/VisageTracker Configuration Manual.pdf&quot;&gt;tracker configuration&lt;/a&gt; file</span>
<a name="l00625"></a>00625 <span class="comment">        * corresponds to the real camera used the scale of the coordinates shall be correct, in meters; otherwise the scale of the translation values is not known, but the relative values are still correct (i.e. moving towards the camera results in negative values of z coordinate).</span>
<a name="l00626"></a>00626 <span class="comment">        * The absolute translation, rotation returned by getFaceRotation() and the camera focus value FBFT::f together form the 3D coordinate system of the head in its current position</span>
<a name="l00627"></a>00627 <span class="comment">        * and they can be used to align 3D rendered objects with the head for AR or similar applications. The relative facial feature coordinates returned by getFeaturePoints()</span>
<a name="l00628"></a>00628 <span class="comment">        * can be used to align rendered 3D objects to the specific features of the face, like putting virtual eyeglasses on the eyes.</span>
<a name="l00629"></a>00629 <span class="comment">        *</span>
<a name="l00630"></a>00630 <span class="comment">        *</span>
<a name="l00631"></a>00631 <span class="comment">        * @param relative if true, function returns relative translation from the position in the initial video frame; otherwise it returns absolute translation (from the camera).</span>
<a name="l00632"></a>00632 <span class="comment">        * @param compensated if true, and if &quot;relative&quot; is also true, function returns compensated translation, otherwise it returns uncompensated translation.</span>
<a name="l00633"></a>00633 <span class="comment">        * @return pointer to the array with the x, y, z translation values.</span>
<a name="l00634"></a>00634 <span class="comment">        *</span>
<a name="l00635"></a>00635 <span class="comment">        * @see translation_compensation_factor</span>
<a name="l00636"></a>00636 <span class="comment">        * @see getFaceRotation()</span>
<a name="l00637"></a>00637 <span class="comment">        * @see getFeaturePoints()</span>
<a name="l00638"></a>00638 <span class="comment">        * @see FBFT</span>
<a name="l00639"></a>00639 <span class="comment">        */</span>
<a name="l00640"></a>00640         <span class="keywordtype">float</span> *getFaceTranslation(<span class="keywordtype">bool</span> relative, <span class="keywordtype">bool</span> compensated);
<a name="l00641"></a>00641 
<a name="l00642"></a>00642 
<a name="l00643"></a>00643         <span class="comment">/* Get the textured 3D model of the face (head) in current pose.</span>
<a name="l00644"></a>00644 <span class="comment">        *</span>
<a name="l00645"></a>00645 <span class="comment">        * This method is currently experimental and has not been fully tested.</span>
<a name="l00646"></a>00646 <span class="comment">        *</span>
<a name="l00647"></a>00647 <span class="comment">        * This method returns the 3D model internally used by the tracker. The model is fitted in 3D to the</span>
<a name="l00648"></a>00648 <span class="comment">        * face in the current video frame. The model is a single textured 3D triangle mesh.</span>
<a name="l00649"></a>00649 <span class="comment">        *</span>
<a name="l00650"></a>00650 <span class="comment">        * The texture of the model is the current video frame. This means that, when the model is drawn using the correct</span>
<a name="l00651"></a>00651 <span class="comment">        * perspective (defined by focal length f, image width and height and model rotation and translation), it exactly recreates the facial part of the image. This can be used, for example, to</span>
<a name="l00652"></a>00652 <span class="comment">        * cut out the face from the rest of the image (NOTE: if this is the desired effect, the model with closed mouth should be used otherwise when the mouth opens a hole appears.</span>
<a name="l00653"></a>00653 <span class="comment">        * The model candide3-ClosedMouth.wfm is provided for this purpose and should simply be specified instead of the default Candide3.wfm in the model_filename statement in the tracker configuration file).</span>
<a name="l00654"></a>00654 <span class="comment">        *</span>
<a name="l00655"></a>00655 <span class="comment">        * There are multiple potential uses for this function. Some ideas include, but are not limited to:</span>
<a name="l00656"></a>00656 <span class="comment">        *</span>
<a name="l00657"></a>00657 <span class="comment">        * - Draw the model into the Z buffer to achieve correct occlusion of virtual objects by the head in AR applications.</span>
<a name="l00658"></a>00658 <span class="comment">        * - Use texture coordinates to cut out the face from the image.</span>
<a name="l00659"></a>00659 <span class="comment">        * - Draw the 3D model from a different perspective than the one in the actual video.</span>
<a name="l00660"></a>00660 <span class="comment">        * - Insert the model into another video or 3D scene.</span>
<a name="l00661"></a>00661 <span class="comment">        *</span>
<a name="l00662"></a>00662 <span class="comment">        * Note that smoothing parameters are not applied to any values returned by this function.</span>
<a name="l00663"></a>00663 <span class="comment">        *</span>
<a name="l00664"></a>00664 <span class="comment">        * @param trans 3D translation of the head (equivalent to calling getFaceTranslation(false, false) except that this function returns original values without any smoothing, while getFaceTranslation() returns smoothed values if smoothing filter is on).</span>
<a name="l00665"></a>00665 <span class="comment">        * @param rot 3D rotation of the head (equivalent to calling getFaceRotation(false) except that this function returns original values without any smoothing, while getFaceTranslation() returns smoothed values if smoothing filter is on).</span>
<a name="l00666"></a>00666 <span class="comment">        * @param f Camera focal lenght, to be used in setting the perspective if the 3D model has to be rendered correctly aligned with current video image.</span>
<a name="l00667"></a>00667 <span class="comment">        * @param img_width Width of the current video image, which is also the texture for the 3D model.</span>
<a name="l00668"></a>00668 <span class="comment">        * @param img_height Height of the current video image, which is also the texture for the 3D model.</span>
<a name="l00669"></a>00669 <span class="comment">        * @param tex_img The current video image, which is also the texture for the 3D model. IplImage is the image storage class from OpenCV, please refer to OpenCV documentation for details of accessing its data members; the basic members are the size of the image (frame-&gt;width, frame-&gt;height) and the pointer to the actual pixel data of the image (frame-&gt;imageData).</span>
<a name="l00670"></a>00670 <span class="comment">        * @param n_vert Number of vertices in the 3D model.</span>
<a name="l00671"></a>00671 <span class="comment">        * @param vert List of vertex coordinates of the 3D model, x y and z coordinate for each vertex.</span>
<a name="l00672"></a>00672 <span class="comment">        * @param n_tri Number of triangles in the model.</span>
<a name="l00673"></a>00673 <span class="comment">        * @param tri Triangles list Each triangle is described by three indices into the list of vertices vert. Counter-clockwise convention is used for normals direction.</span>
<a name="l00674"></a>00674 <span class="comment">        * @param tex_coord Texture coordinates for the model, a pair of u, v coordinates for each vertex.</span>
<a name="l00675"></a>00675 <span class="comment">        * @return true on success, false if the model can not be returned because the tracker is not active or the face is currently not detected in the video frame.</span>
<a name="l00676"></a>00676 <span class="comment">        *</span>
<a name="l00677"></a>00677 <span class="comment">        * @see getFaceTranslation(), getFaceRotation), VisageSDK::FBFT::f</span>
<a name="l00678"></a>00678 <span class="comment">        */</span>
<a name="l00679"></a>00679         <span class="keywordtype">bool</span> getFaceModel(<span class="keyword">const</span> <span class="keywordtype">float</span>* &amp;trans, <span class="keyword">const</span> <span class="keywordtype">float</span>* &amp;rot, <span class="keywordtype">float</span> &amp;f, <span class="keywordtype">int</span> &amp;img_width, <span class="keywordtype">int</span> &amp;img_height, <span class="keyword">const</span> IplImage* &amp;tex_img, <span class="keywordtype">int</span> &amp;n_vert, <span class="keyword">const</span> <span class="keywordtype">float</span>* &amp;vert,<span class="keywordtype">int</span> &amp;n_tri, <span class="keyword">const</span> <span class="keywordtype">int</span>* &amp;tri, <span class="keyword">const</span> <span class="keywordtype">float</span>* &amp;tex_coord);
<a name="l00680"></a>00680 
<a name="l00681"></a>00681         <span class="comment">/* Get the current video frame.</span>
<a name="l00682"></a>00682 <span class="comment">        *</span>
<a name="l00683"></a>00683 <span class="comment">        * IplImage is the image storage class from OpenCV, please refer to OpenCV documentation for details of accessing its data members; the basic members are the size of the image (frame-&gt;width, frame-&gt;height) and the pointer to the actual pixel data of the image (frame-&gt;imageData).</span>
<a name="l00684"></a>00684 <span class="comment">        *</span>
<a name="l00685"></a>00685 <span class="comment">        * @return pointer to the current video frame, or NULL if tracker is not active.</span>
<a name="l00686"></a>00686 <span class="comment">        */</span>
<a name="l00687"></a>00687          <span class="keyword">const</span> IplImage *getCurrentVideoFrame(){<span class="keywordflow">return</span>(isActive() ? (<span class="keyword">const</span> IplImage *)frame_input : NULL);};
<a name="l00688"></a>00688 
<a name="l00695"></a>00695         <span class="keywordtype">void</span> start(<span class="keywordtype">long</span> globalTime);
<a name="l00696"></a>00696 
<a name="l00702"></a>00702         <span class="keywordtype">void</span> stop();
<a name="l00703"></a>00703 
<a name="l00707"></a><a class="code" href="classVisageSDK_1_1VisageTracker2.html#a53765c77a7a5df057d9874abb48e6e92">00707</a>         <span class="keywordtype">char</span>* <a class="code" href="classVisageSDK_1_1VisageTracker2.html#a53765c77a7a5df057d9874abb48e6e92" title="Action name (FbaAction implementation).">actionTypeName</a>() {<span class="keywordflow">return</span> <span class="stringliteral">&quot;VisageTracker2&quot;</span>;};
<a name="l00708"></a>00708 
<a name="l00709"></a>00709         <span class="comment">/*</span>
<a name="l00710"></a>00710 <span class="comment">        * Set the upper and lower limit for each of Facial Animation Parameters, i.e., the maximum and minimum allowed values for</span>
<a name="l00711"></a>00711 <span class="comment">        * each of the 68 FAPs. The tracker will cut off any values outside these limits.</span>
<a name="l00712"></a>00712 <span class="comment">        *</span>
<a name="l00713"></a>00713 <span class="comment">        * Initially it is set to a very large range so the limits will not be reached in practice.</span>
<a name="l00714"></a>00714 <span class="comment">        *</span>
<a name="l00715"></a>00715 <span class="comment">        * @param upperLimit pointer to the FAPs object containing the upper FAP limits</span>
<a name="l00716"></a>00716 <span class="comment">        * @param lowerLimit pointer to the FAPs object containing the lower FAP limits</span>
<a name="l00717"></a>00717 <span class="comment">        * @see getUpperFAPLimits(), getLowerFAPLimits()</span>
<a name="l00718"></a>00718 <span class="comment">        */</span>
<a name="l00719"></a>00719         <span class="keywordtype">void</span> setFAPLimits(FAPs *upperLimit, FAPs *lowerLimit);
<a name="l00720"></a>00720 
<a name="l00721"></a>00721         <span class="comment">/*</span>
<a name="l00722"></a>00722 <span class="comment">        * Returns the pointer to the FAPs object containing the upper FAP limits</span>
<a name="l00723"></a>00723 <span class="comment">        * @return the upper FAP limits.</span>
<a name="l00724"></a>00724 <span class="comment">        */</span>
<a name="l00725"></a>00725         FAPs *getUpperFAPLimits();
<a name="l00726"></a>00726 
<a name="l00727"></a>00727         <span class="comment">/*</span>
<a name="l00728"></a>00728 <span class="comment">        * Returns the pointer to the FAPs object containing the lower FAP limits.</span>
<a name="l00729"></a>00729 <span class="comment">        * See setFAPLimits() for details regarding the FAP limitation mechanism.</span>
<a name="l00730"></a>00730 <span class="comment">        * @return the lower FAP limits.</span>
<a name="l00731"></a>00731 <span class="comment">        */</span>
<a name="l00732"></a>00732         FAPs *getLowerFAPLimits();
<a name="l00733"></a>00733 
<a name="l00746"></a>00746         <span class="keywordtype">bool</span> DetectStrip(<span class="keywordtype">double</span> &amp;size);
<a name="l00747"></a>00747 
<a name="l00757"></a>00757         <span class="keywordtype">void</span> setIPD(<span class="keywordtype">float</span> value);
<a name="l00758"></a>00758 
<a name="l00765"></a>00765         <span class="keywordtype">float</span> getIPD();
<a name="l00766"></a>00766     
<a name="l00767"></a>00767 <span class="preprocessor">#ifdef IOS</span>
<a name="l00768"></a>00768 <span class="preprocessor"></span>
<a name="l00773"></a>00773     <span class="keywordtype">void</span> setDataBundle(NSBundle *bundle);
<a name="l00774"></a>00774 <span class="preprocessor">#endif</span>
<a name="l00775"></a>00775 <span class="preprocessor"></span>
<a name="l00776"></a>00776         <a class="code" href="classVisageSDK_1_1TrackerOpenGLInterface.html" title="Optional OpenGL Interface for VisageTracker2.">TrackerOpenGLInterface</a> *oglIface;
<a name="l00777"></a>00777         <a class="code" href="classVisageSDK_1_1TrackerGUIInterface.html" title="Optional GUI Interface for VisageTracker2.">TrackerGUIInterface</a> *guiIface;
<a name="l00778"></a>00778         TrackerInternalInterface *internalIface;
<a name="l00779"></a>00779         <span class="keywordtype">void</span> display_func();
<a name="l00780"></a>00780 
<a name="l00781"></a>00781         <span class="comment">//read scale and shape units from file</span>
<a name="l00782"></a>00782         <span class="keywordtype">void</span> read_profile (
<a name="l00783"></a>00783                 <span class="keyword">const</span> <span class="keywordtype">string</span> &amp;filename
<a name="l00784"></a>00784                 );
<a name="l00785"></a>00785         <span class="comment">//write scale and shape units to file</span>
<a name="l00786"></a>00786         <span class="keywordtype">void</span> write_profile (
<a name="l00787"></a>00787                 <span class="keyword">const</span> <span class="keywordtype">string</span> &amp;filename
<a name="l00788"></a>00788                 );
<a name="l00789"></a>00789 
<a name="l00790"></a>00790         <span class="comment">//write scale and shape units to file, using the current file name</span>
<a name="l00791"></a>00791         <span class="keywordtype">void</span> write_profile (
<a name="l00792"></a>00792                 );
<a name="l00793"></a>00793 
<a name="l00794"></a>00794         <span class="keywordtype">int</span> auto_init; <span class="comment">/* Control the automatic initialisation. 0 = semi-automatic initialisation of the tracker; 1 = fully automatic tracking with fast initialisation. Initially it is set through the &lt;a href=&quot;doc/VisageTracker Configuration Manual.pdf&quot;&gt;tracker configuration&lt;/a&gt; file.*/</span>
<a name="l00795"></a>00795 
<a name="l00796"></a>00796         <span class="keywordtype">int</span> manual_face_detection; <span class="comment">/* When set to 1, the tracker disables the automatic detection of the face during the tracking initialization and instead it presents the image to the user and asks the user to click on the eyes,nose tip and mouth corners. This is used for videos in which automatic face detection does not work, so tracking can not start; manually picking the face allows the tracker to initialise and then it continues tracking. For example, this is the case with thermal videos and sometimes with videos where the face wears some painted markers; it has sometimes happened with videos of old people.</span>
<a name="l00797"></a>00797 <span class="comment">The function for manual feature picking is implemented through the TrackerGUIInterface abstract interface class; it is provided with full source code and developers can modify or replace it wih different picking methods, or even with their own automatic detection method. If this option is set to 0, automatic face detection is used. Initially it is set through the &lt;a href=&quot;#config&quot;&gt;tracker configuration file&lt;/a&gt;.*/</span>
<a name="l00798"></a>00798 
<a name="l00799"></a>00799         <span class="keywordtype">float</span> init_pose_dev; <span class="comment">/* Allowed deviation from ideal initialisation pose. This value is used only in automatic initialisation mode. It controls the level of quality of the head pose that triggers the initialisation of the tracker. The value of 0 means the tracker will require the best head pose before it starts; higher values relay the requirements.*/</span>
<a name="l00800"></a>00800         <span class="keywordtype">float</span> init_yaw_threshold; <span class="comment">/* This value is used during automatic initialisation or, in manual initialization mode while the tracker initially searches for the best frame on which to perform initialization. It controls the amount of yaw (left-right rotation of the head) allowed at initialisation; the tracker waits until the head pose is within this limit before it initialises and starts tracking. The value of 0 means the tracker will require perfectly frontal head pose before it starts (it is not recommended to set it to 0 because the tracker may then never start); higher values relax the requirements.*/</span>
<a name="l00801"></a>00801         <span class="keywordtype">float</span> init_roll_threshold; <span class="comment">/* This value is used during automatic initialisation or, in manual initialization mode while the tracker initially searches for the best frame on which to perform initialization. It controls the amount of roll (tilt of the head) allowed at initialisation; the tracker waits until the head pose is within this limit before it initialises and starts tracking. The value of 0 means the tracker will require perfectly frontal head pose before it starts (it is not recommended to set it to 0 because the tracker may then never start); higher values relax the requirements. */</span>
<a name="l00802"></a>00802         <span class="keywordtype">float</span> init_velocity_threshold; <span class="comment">/* This value is used only in automatic initialisation mode. It controls the speed of head movement allowed at initialisation; the tracker waits until the head stabilises below this speed limit before it initialises and starts tracking. It is expressed in meters per second. The value of 0 means the tracker will require perfectly still head before it starts (it is not recommended to set it to 0 because the tracker may then never start); higher values relax the requirements. */</span>
<a name="l00803"></a>00803         <span class="keywordtype">float</span> init_timeout; <span class="comment">/* This value is used only in automatic initialisation mode. It controls the time allowed at initialisation, in milliseconds. If the desired head pose was not found during this time, the tracker chooses the best available image seen during this time. The timing starts from the moment when face is detected.*/</span>
<a name="l00804"></a>00804         <span class="keywordtype">int</span> init_timeout_enable; <span class="comment">/* This value is used during automatic initialisation or, in manual initialization mode while the tracker initially searches for the best frame on which to perform initialization. It enables or disables the initialization timeout mechanism; when it is disabled, the parameter init_timeout (see above) is ignored and initialization continues until the desired head pose is reached. The setting is separate for camera, video file and raw image input modes and determined by the first, second and third bit of the value, respectively. Thus value 1 means that the timeout mechanism is enabled when tracking from camera; 2 means it is enabled when tracking from video file; 4 means it is enabled when using the raw image interface and 0 means it is always disabled; combinations are allowed, e.g. 6 enables timeout in video and raw image input modes.*/</span>
<a name="l00805"></a>00805         <span class="keywordtype">int</span> init_display_status; <span class="comment">/* This value is used during automatic initialisation or, in manual initialization mode while the tracker initially searches for the best frame on which to perform initialization. It enables or disables the initialization status display. When enabled, the initialization status is displayed interactively on the screen during initialization in order to help the user to position the head. The setting is separate for camera, video file and raw image input modes and determined by the first, second and third bit of the value, respectively. Thus value 1 means that the display is enabled when tracking from camera; 2 means it is enabled when tracking from video file; 4 means it is enabled when using the raw image interface and 0 means it is always disabled; combinations are allowed, e.g. 6 enables display in video and raw image input modes.*/</span>
<a name="l00806"></a>00806         <span class="keywordtype">float</span> recovery_timeout; <span class="comment">/* This value is used only in automatic initialisation mode. It is used when the tracker looses the face and can not detect any face in the frame. This value tells the tracker how long it should wait before considering that the current user is gone and initialising the full re-initialisation procedure.  If the face is detected before this time elapses, the tracker considers that it is the same person and it recovers, i.e. continues tracking it using the previous settings. The time is expressed in milliseconds. */</span>
<a name="l00807"></a>00807 
<a name="l00808"></a>00808         <span class="keywordtype">bool</span> display_video; <span class="comment">/* Toggle video display on/off; initially it is set through the&lt;a href=&quot;doc/VisageTracker Configuration Manual.pdf&quot;&gt;tracker configuration&lt;/a&gt; file and usually it is on, so video will be visible while tracking. */</span>
<a name="l00809"></a>00809         <span class="keywordtype">bool</span> display_model_texture; <span class="comment">/* Toggle model texture display on/off; initially it is set through the &lt;a href=&quot;doc/VisageTracker Configuration Manual.pdf&quot;&gt;tracker configuration&lt;/a&gt; file. */</span>
<a name="l00810"></a>00810         <span class="keywordtype">bool</span> display_tri_mask; <span class="comment">/* Toggle triangle mask display on/off (triangle mask determines where track points are looked for); initially it is set through the &lt;a href=&quot;doc/VisageTracker Configuration Manual.pdf&quot;&gt;tracker configuration&lt;/a&gt; file. */</span>
<a name="l00811"></a>00811         <span class="keywordtype">bool</span> display_model_wireframe; <span class="comment">/* Toggle wireframe model display on/off; initially it is set through the &lt;a href=&quot;#config&quot;&gt;tracker configuration file&lt;/a&gt;. */</span>
<a name="l00812"></a>00812         <span class="keywordtype">int</span> display_results; <span class="comment">/* Control the display of tracking results. 0 = no results display; 1 = display tracked feature points; 2 = display head pose; 4 = display eye locations; values can be added together (e.g. 6 = display head pose and eye locations). Initially it is set through the &lt;a href=&quot;doc/VisageTracker Configuration Manual.pdf&quot;&gt;tracker configuration&lt;/a&gt; file. */</span>
<a name="l00813"></a>00813         <span class="keywordtype">bool</span> display_track_points; <span class="comment">/* Toggle the display of track points on/off (track points are automatically found points in the face that are suitable for tracking - they are not the same as feature points and their display is mainly useful for monitoring the functioning of the tracker); initially it is set through the &lt;a href=&quot;#config&quot;&gt;tracker configuration file&lt;/a&gt;.. */</span>
<a name="l00814"></a>00814 
<a name="l00815"></a>00815         <span class="keywordtype">float</span> translation_compensation_factor; <span class="comment">/* Compensation factor for translation results. Default value is 1.0. Bigger values result in more compensation being applied. If it is set to 0, no compensation is applied. For details about translation compensation see getFaceTranslation()*/</span>
<a name="l00816"></a>00816 
<a name="l00817"></a>00817         <span class="keywordtype">int</span> smoothing_translation; <span class="comment">/* Smoothing value for translation results. It must be set between 0 (no smoothing) and 10 (maximal smoothing). Initially it is set through the &lt;a href=&quot;doc/VisageTracker Configuration Manual.pdf&quot;&gt;tracker configuration&lt;/a&gt; file.. Smoothing reduces tracking noise and makes results smoother but it introduces delay so it should be used with caution.*/</span>
<a name="l00818"></a>00818         <span class="keywordtype">int</span> smoothing_rotation; <span class="comment">/* Smoothing value for rotation results. It must be set between 0 (no smoothing) and 10 (maximal smoothing). Initially it is set through the &lt;a href=&quot;doc/VisageTracker Configuration Manual.pdf&quot;&gt;tracker configuration&lt;/a&gt; file.  Smoothing reduces tracking noise and makes results smoother but it introduces delay so it should be used with caution.*/</span>
<a name="l00819"></a>00819         <span class="keywordtype">int</span> smoothing_fp; <span class="comment">/* Smoothing value for feature point results. It must be set between 0 (no smoothing) and 10 (maximal smoothing). Initially it is set through the &lt;a href=&quot;doc/VisageTracker Configuration Manual.pdf&quot;&gt;tracker configuration&lt;/a&gt; file.  Smoothing reduces tracking noise and makes results smoother but it introduces delay so it should be used with caution.*/</span>
<a name="l00820"></a>00820         <span class="keywordtype">int</span> video_file_sync; <span class="comment">/* Synchronisation of video playback from file.</span>
<a name="l00821"></a>00821 <span class="comment"> If set to 0, all video frames are processed and displayed so the effective video playback speed</span>
<a name="l00822"></a>00822 <span class="comment"> depends on the available processing power - on a slow computer playback will be slower than real time, while on a fast</span>
<a name="l00823"></a>00823 <span class="comment"> computer it may be faster. If the flag is set to 1 playback is synchronised by</span>
<a name="l00824"></a>00824 <span class="comment"> skipping video frames or introducing delay as needed, so the video file is played at</span>
<a name="l00825"></a>00825 <span class="comment"> its normal speed. This may deteriorate tracking results on slower computers because video</span>
<a name="l00826"></a>00826 <span class="comment"> frames are skipped. */</span>
<a name="l00827"></a>00827 
<a name="l00828"></a>00828 <span class="comment">// changed to public due to new user interface implementation</span>
<a name="l00829"></a>00829 <span class="comment">// TO DO: verify if all this really must be public</span>
<a name="l00830"></a>00830 
<a name="l00831"></a>00831         <span class="keyword">friend</span> <span class="keyword">class </span>FBFT;
<a name="l00832"></a>00832 
<a name="l00833"></a>00833         FBFT *fbft; <span class="comment">/* Tracker engine implementation. */</span>
<a name="l00834"></a>00834         IplImage* frame_input; <span class="comment">// Current video frame, input; may be color or grayscale</span>
<a name="l00835"></a>00835         IplImage* frame_gray; <span class="comment">// Current video frame converted to grayscale; all processing is done on grayscale images</span>
<a name="l00836"></a>00836         IplImage* best_frame; <span class="comment">// Frame with best pose found during initialisation; grayscale; used only during initialisation</span>
<a name="l00837"></a>00837         IplImage* gl_image; <span class="comment">// OpenGL window image, used for presenting the video image in the OpenGL window.</span>
<a name="l00838"></a>00838         IplImage* gl_image_gray; <span class="comment">// OpenGL window image, grayscale, used for presenting grayscale video image in the OpenGL window.</span>
<a name="l00839"></a>00839         <span class="keywordtype">bool</span> PoseTestTimedOut; <span class="comment">//PoseTestTimedOut is set to true if pose test in WaitFrontalPose finished with a timeout or false if pose test found good pose.</span>
<a name="l00840"></a>00840         <span class="comment">//Variables used for debugging, usually in batch processing mode from FaceTracker2; if set to -1 they are not used (that is the default)</span>
<a name="l00841"></a>00841         <span class="keywordtype">int</span> startFrame; <span class="comment">// start processing video from this frame</span>
<a name="l00842"></a>00842         <span class="keywordtype">int</span> endFrame; <span class="comment">// end processing at this frame</span>
<a name="l00843"></a>00843         <span class="keywordtype">int</span> slowdownFrame; <span class="comment">//insert pause to slow down for debugging from this frame</span>
<a name="l00844"></a>00844         <span class="keywordtype">int</span> slowdownTime;  <span class="comment">// slow down each frame by this time, in milliseconds</span>
<a name="l00845"></a>00845 
<a name="l00846"></a>00846         <span class="keywordtype">bool</span> IsAutoStopped; <span class="comment">// reason for stopping</span>
<a name="l00847"></a>00847         <span class="keywordtype">float</span> VideoFrameRate;
<a name="l00848"></a>00848 
<a name="l00849"></a>00849         <span class="keywordtype">int</span> Update(<span class="keywordtype">void</span>);
<a name="l00850"></a>00850         <span class="keywordtype">void</span> Finish(<span class="keywordtype">void</span>);
<a name="l00851"></a>00851 
<a name="l00852"></a>00852         <span class="keywordtype">float</span> targetFps;
<a name="l00853"></a>00853 
<a name="l00854"></a>00854 <span class="keyword">private</span>:
<a name="l00855"></a>00855         <span class="keywordtype">int</span> skippedCount;
<a name="l00856"></a>00856         <span class="keywordtype">int</span> foundCount;
<a name="l00857"></a>00857         <span class="keywordtype">float</span> videoFps;
<a name="l00858"></a>00858 
<a name="l00859"></a>00859         <span class="keywordtype">float</span> detectStripAreaThreshold;
<a name="l00860"></a>00860         <span class="keywordtype">float</span> detectStripPerfectRatio;
<a name="l00861"></a>00861         <span class="keywordtype">float</span> detectStripRatioThreshold;
<a name="l00862"></a>00862         <span class="keywordtype">float</span> detectStripAngleThreshold;
<a name="l00863"></a>00863         <span class="keywordtype">float</span> detectStripRoiYOffset;
<a name="l00864"></a>00864         <span class="keywordtype">float</span> detectStripRoiWidth;
<a name="l00865"></a>00865         <span class="keywordtype">float</span> detectStripRoiHeight;
<a name="l00866"></a>00866 
<a name="l00867"></a>00867         <span class="keywordtype">float</span> bdts_trees_factor;
<a name="l00868"></a>00868 
<a name="l00869"></a>00869         SmoothingFilter sf;
<a name="l00870"></a>00870         <span class="comment">//VisageFeaturesDetector *m_Detector;</span>
<a name="l00871"></a>00871         VisageDetector *m_Detector;
<a name="l00872"></a>00872 
<a name="l00873"></a>00873         <span class="keywordtype">long</span> getCurrentTimeMs(<span class="keywordtype">bool</span> init);
<a name="l00874"></a>00874 
<a name="l00875"></a>00875         <span class="keywordtype">bool</span> grabFrame(<span class="keywordtype">bool</span> init);
<a name="l00876"></a>00876 
<a name="l00877"></a>00877         IplImage *frame_buffers[3];
<a name="l00878"></a>00878         <span class="keywordtype">int</span> a_frame;
<a name="l00879"></a>00879         <span class="keywordtype">int</span> p_frame;
<a name="l00880"></a>00880         <span class="keywordtype">int</span> v_frame;
<a name="l00881"></a>00881 
<a name="l00882"></a>00882         <span class="keywordtype">bool</span> waitFrontalPose(<a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *latestFP,<a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *bestFP, <span class="keywordtype">bool</span> strict,<span class="keywordtype">bool</span> &amp;presenceTest,<span class="keywordtype">bool</span> poseTest,<span class="keywordtype">int</span> parts=VS_FACE);
<a name="l00883"></a>00883         <span class="keywordtype">bool</span> fitModelToFace(<a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *latestFP,<span class="keywordtype">bool</span> init_tracker);
<a name="l00884"></a>00884         <span class="keywordtype">bool</span> fitModelToFaceNew(<a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *latestFP, <span class="keywordtype">bool</span> init_tracker, <span class="keywordtype">bool</span> reinit = <span class="keyword">false</span>);
<a name="l00885"></a>00885         <span class="keywordtype">bool</span> verifyPose(<a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *f);
<a name="l00886"></a>00886     <span class="keywordtype">bool</span> testPose(<a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *f, <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *best);
<a name="l00887"></a>00887     <span class="keywordtype">bool</span> refitModelToFace();
<a name="l00888"></a>00888 
<a name="l00889"></a>00889         <span class="keyword">static</span> <span class="keywordtype">void</span>  trackInThread(<span class="keywordtype">void</span>* vt);
<a name="l00890"></a>00890         <span class="keywordtype">void</span> writeBits(FILE *streamHandle, <span class="keywordtype">unsigned</span> <span class="keywordtype">char</span> *bits, <span class="keywordtype">int</span> size);<span class="comment">//void writeBits(int streamHandle, unsigned char *bits, int size);</span>
<a name="l00891"></a>00891 
<a name="l00892"></a>00892         <span class="keyword">static</span> <span class="keywordtype">void</span> trackInThread2(<span class="keywordtype">void</span>* vt);
<a name="l00893"></a>00893 
<a name="l00894"></a>00894         <span class="keywordtype">int</span> Init(<span class="keywordtype">void</span>);
<a name="l00895"></a>00895 
<a name="l00896"></a>00896         <span class="keywordtype">bool</span> testFrontalPose(<a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *latestFP, <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *bestFP,<span class="keywordtype">int</span> parts=VS_FACE);
<a name="l00897"></a>00897 
<a name="l00898"></a>00898         <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *tmpLatestFP;
<a name="l00899"></a>00899         <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *tmpBestFP;
<a name="l00900"></a>00900         <span class="keywordtype">bool</span> presenceTest;
<a name="l00901"></a>00901         <span class="keywordtype">int</span> faceLostTime; <span class="comment">//time when face was lost from view</span>
<a name="l00902"></a>00902         <span class="keywordtype">int</span> faceFoundTime; <span class="comment">//time when face was detected</span>
<a name="l00903"></a>00903         <span class="keywordtype">float</span> bestPoseValue;
<a name="l00904"></a>00904         <span class="keywordtype">int</span> profile_loaded;
<a name="l00905"></a>00905         <span class="keywordtype">int</span> trackerState;
<a name="l00906"></a>00906 
<a name="l00907"></a>00907         <span class="keywordtype">bool</span> debug_frame_pause;
<a name="l00908"></a>00908     <span class="keywordtype">bool</span> texInited;
<a name="l00909"></a>00909 
<a name="l00910"></a>00910         <span class="comment">//source video filename</span>
<a name="l00911"></a>00911         <span class="keywordtype">char</span> source[500];
<a name="l00912"></a>00912 
<a name="l00913"></a>00913         <span class="comment">// frame grabber interface</span>
<a name="l00914"></a>00914         <a class="code" href="classVisageSDK_1_1VisageTrackerFrameGrabber.html" title="VisageTrackerFrameGrabber interface.">VisageTrackerFrameGrabber</a> *frameGrabber;
<a name="l00915"></a>00915         <span class="keywordtype">int</span> frameGrabberImageFormat; <span class="comment">//image format for the frame grabber image (RGB, BGR or LUMINANCE)</span>
<a name="l00916"></a>00916 
<a name="l00917"></a>00917         <span class="keywordtype">long</span> globalStartTime;
<a name="l00918"></a>00918 
<a name="l00919"></a>00919         <span class="comment">//interesting FAP groups are 2,3,4,5,8 (actually 1,2,3,4,7 as the counting starts from 0)</span>
<a name="l00920"></a>00920         FBAPs *fbaps; 
<a name="l00921"></a>00921         FBAPs *fbaps0;
<a name="l00922"></a>00922         <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a>* fdps;
<a name="l00924"></a>00924         FAPs* upperLimits;
<a name="l00925"></a>00925         FAPs* lowerLimits;
<a name="l00926"></a>00926 
<a name="l00927"></a>00927         <a class="code" href="classVisageSDK_1_1VisageTrackerObserver.html" title="VisageTrackerObserver interface.">VisageTrackerObserver</a> *obs[100];
<a name="l00928"></a>00928         <span class="keywordtype">int</span> nObs; 
<a name="l00930"></a>00930         <span class="comment">//initial face rotation and translation</span>
<a name="l00931"></a>00931         <span class="keywordtype">float</span> init_face_translation[3];
<a name="l00932"></a>00932         <span class="keywordtype">float</span> init_face_rotation[3];
<a name="l00933"></a>00933 
<a name="l00934"></a>00934         <span class="comment">//face rotation and translation</span>
<a name="l00935"></a>00935         <span class="keywordtype">float</span> face_translation_rel[3];
<a name="l00936"></a>00936         <span class="keywordtype">float</span> face_translation_abs[3];
<a name="l00937"></a>00937         <span class="keywordtype">float</span> face_translation_comp[3];
<a name="l00938"></a>00938         <span class="keywordtype">float</span> face_rotation[3];
<a name="l00939"></a>00939         <span class="keywordtype">float</span> face_rotation_not_smoothed[3];
<a name="l00940"></a>00940 
<a name="l00941"></a>00941         <span class="comment">// values holding the initialization status</span>
<a name="l00942"></a>00942         <span class="keywordtype">bool</span> init_face_detected;
<a name="l00943"></a>00943         <span class="keywordtype">float</span> init_yaw;
<a name="l00944"></a>00944         <span class="keywordtype">float</span> init_roll;
<a name="l00945"></a>00945         <span class="keywordtype">float</span> init_velocity;
<a name="l00946"></a>00946 
<a name="l00947"></a>00947         <span class="comment">//various flags</span>
<a name="l00948"></a>00948         <span class="keyword">volatile</span> <span class="keywordtype">bool</span> active;
<a name="l00949"></a>00949         <span class="keyword">volatile</span> <span class="keywordtype">bool</span> inThread;
<a name="l00950"></a>00950         <span class="keywordtype">bool</span> toFile;
<a name="l00951"></a>00951         <span class="keywordtype">bool</span> editing; <span class="comment">//used by display function; when true, display function ignores other display flags and displays only the wireframe model for editing</span>
<a name="l00952"></a>00952         <span class="keywordtype">bool</span> fitting; <span class="comment">//used by display function to display the wireframe model in different color while face fitting process is on, mainly for debugging purposes</span>
<a name="l00953"></a>00953         HANDLE trackingThreadHandle;
<a name="l00954"></a>00954         HANDLE detectorThreadHandle;
<a name="l00955"></a>00955         CvCapture* capture;
<a name="l00956"></a>00956 <span class="preprocessor">#ifdef WIN32</span>
<a name="l00957"></a>00957 <span class="preprocessor"></span>        videoInput *VI; 
<a name="l00958"></a>00958 <span class="preprocessor">#endif</span>
<a name="l00959"></a>00959 <span class="preprocessor"></span><span class="preprocessor">#ifdef IOS</span>
<a name="l00960"></a>00960 <span class="preprocessor"></span>        iOSCapture *IC;
<a name="l00961"></a>00961 <span class="preprocessor">#endif</span>
<a name="l00962"></a>00962 <span class="preprocessor"></span><span class="preprocessor">#ifdef MAC_OS_X</span>
<a name="l00963"></a>00963 <span class="preprocessor"></span>    OSXCapture *OSXInput;
<a name="l00964"></a>00964 <span class="preprocessor">#endif</span>
<a name="l00965"></a>00965 <span class="preprocessor"></span>     
<a name="l00966"></a>00966         <span class="keywordtype">bool</span> tex_too_small; <span class="comment">// video frame dimensions are bigger than max supported tex size</span>
<a name="l00967"></a>00967 
<a name="l00968"></a>00968         CFBAEncoder* fbaEncoder;
<a name="l00969"></a>00969         FILE *fbaFileHandle;<span class="comment">//int fbaFileHandle;/*!handle for the FBA file*/</span>
<a name="l00970"></a>00970 
<a name="l00971"></a>00971         <span class="keywordtype">char</span> fbaFileName[500];
<a name="l00974"></a>00974         <span class="keywordtype">unsigned</span> <span class="keywordtype">char</span> byte;
<a name="l00975"></a>00975         <span class="keywordtype">int</span> bitcnt;
<a name="l00976"></a>00976 
<a name="l00977"></a>00977         <span class="keywordtype">string</span> profile_filename;
<a name="l00978"></a>00978         <span class="keywordtype">string</span> configuration_filename; <span class="comment">//tracker configuration file</span>
<a name="l00979"></a>00979         <span class="keywordtype">string</span> configuration_filestring; <span class="comment">//tracker configuration file contents</span>
<a name="l00980"></a>00980         <span class="keywordtype">string</span> texture_filename; <span class="comment">// file name for texture (read from profile)</span>
<a name="l00981"></a>00981         <span class="keywordtype">string</span> detector_data_path; <span class="comment">// path to the folder containing Haar cascade files</span>
<a name="l00982"></a>00982 
<a name="l00983"></a>00983         <span class="keywordtype">int</span> frameCount; <span class="comment">// frame count from beginning of tracking</span>
<a name="l00984"></a>00984         <span class="keywordtype">double</span> frameTime; <span class="comment">// duration of one frame in milliseconds</span>
<a name="l00985"></a>00985         <span class="keywordtype">long</span> pts; <span class="comment">// presentation time stamp, calculated by grabFrame()</span>
<a name="l00986"></a>00986         <span class="keywordtype">long</span> pts_data; <span class="comment">// time stamp</span>
<a name="l00987"></a>00987         <span class="keywordtype">int</span> pts_frame;
<a name="l00988"></a>00988 
<a name="l00989"></a>00989         <span class="keywordtype">float</span> gaze[2]; <span class="comment">//gaze direction</span>
<a name="l00990"></a>00990 <span class="preprocessor">#ifdef IOS</span>
<a name="l00991"></a>00991 <span class="preprocessor"></span>    NSBundle *dataBundle;
<a name="l00992"></a>00992 <span class="preprocessor">#endif</span>
<a name="l00993"></a>00993 <span class="preprocessor"></span>
<a name="l00994"></a>00994         <span class="comment">//stuff copied from main.cpp in Nils&#39; original project</span>
<a name="l00995"></a>00995         <span class="keyword">volatile</span> <span class="keywordtype">bool</span> tracking_ok; <span class="comment">//tracking status OK</span>
<a name="l00996"></a>00996         f32 trackingFrameRate; <span class="comment">// measured tracking frame rate</span>
<a name="l00997"></a>00997         iu32 cam_input; <span class="comment">//0: videoinput library; 1: OpenCV</span>
<a name="l00998"></a>00998         iu32 cam_device; <span class="comment">//camera device number</span>
<a name="l00999"></a>00999         iu32 cam_width; <span class="comment">//camera width</span>
<a name="l01000"></a>01000         iu32 cam_height; <span class="comment">//camera height</span>
<a name="l01001"></a>01001         iu32 gl_width; <span class="comment">//width of opengl display window</span>
<a name="l01002"></a>01002         iu32 gl_height; <span class="comment">//height of opengl display window</span>
<a name="l01003"></a>01003         iu32 cam_fps; <span class="comment">//camera frame rate to set</span>
<a name="l01004"></a>01004         iu32 cam_mirror; <span class="comment">// if 1, flip camera image horizontally to achieve mirror effect</span>
<a name="l01005"></a>01005     iu32 cam_flip; <span class="comment">// if 1, flip camera image vertically</span>
<a name="l01006"></a>01006         iu32 cam_settings; <span class="comment">//if 1, show camera settings dialog</span>
<a name="l01007"></a>01007         iu32 cam_auto; <span class="comment">//if 1, do automatic camera settings when tracking starts</span>
<a name="l01008"></a>01008         IplImage* new_frame; <span class="comment">//any new frames</span>
<a name="l01009"></a>01009         <span class="keywordtype">void</span> app_setup();  <span class="comment">// read application settings from configuration file</span>
<a name="l01010"></a>01010         <span class="keywordtype">int</span> load_profile(); <span class="comment">// try to load profile, return 1 on success, 0 if profile not found, -1 if profile found but failed to load</span>
<a name="l01011"></a>01011         <span class="keywordtype">int</span> cam_orientation;
<a name="l01012"></a>01012 
<a name="l01013"></a>01013         <span class="comment">//from func_gl.h</span>
<a name="l01014"></a>01014         <span class="comment">//clear buffer</span>
<a name="l01015"></a>01015         <span class="keywordtype">void</span> gl_clear (
<a name="l01016"></a>01016                 );
<a name="l01017"></a>01017 
<a name="l01018"></a>01018         <span class="comment">//stuff for calculating FAPs and FDPs</span>
<a name="l01019"></a>01019         <span class="keywordtype">float</span> calculateFAPU( <span class="keywordtype">int</span> fapu );
<a name="l01020"></a>01020         <span class="keywordtype">void</span> calculateFAPUs();
<a name="l01021"></a>01021         <span class="keywordtype">float</span> fapuValue[6];
<a name="l01022"></a>01022         <span class="keywordtype">int</span> calculateFAP( <span class="keywordtype">int</span> fap ) ;
<a name="l01023"></a>01023         <span class="keywordtype">void</span> calculateFAPs( FBAPs* fbaps);
<a name="l01024"></a>01024         <span class="keywordtype">void</span> calculateFDP(<a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a>* f, <span class="keywordtype">int</span> w, <span class="keywordtype">int</span> h, CvMat* vert, <span class="keywordtype">bool</span> _3D, <span class="keywordtype">bool</span> use_detected_points = <span class="keyword">false</span>);
<a name="l01025"></a>01025         <span class="keywordtype">void</span> setFDPIndices(<a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a>* f);
<a name="l01026"></a>01026         <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *featurePoints2D;
<a name="l01027"></a>01027         <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *featurePoints3D;
<a name="l01028"></a>01028         <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *featurePoints3DR;
<a name="l01029"></a>01029         <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *origFeaturePoints2D;
<a name="l01030"></a>01030         <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *origFeaturePoints3D;
<a name="l01031"></a>01031         <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *origFeaturePoints3DR;
<a name="l01032"></a>01032         <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *m_bestFP;
<a name="l01033"></a>01033 
<a name="l01034"></a>01034         ModelFitter* modelFitter;
<a name="l01035"></a>01035         <span class="keywordtype">int</span> nFPs; <span class="comment">// number of feature points used for fitting</span>
<a name="l01036"></a>01036 
<a name="l01037"></a>01037         <span class="keywordtype">void</span> initTrackingData(<span class="keywordtype">void</span>);
<a name="l01038"></a>01038         <span class="keywordtype">void</span> swapTrackingData(<span class="keywordtype">void</span>);
<a name="l01039"></a>01039         <span class="keywordtype">void</span> smoothTrackingData(<span class="keywordtype">void</span>);
<a name="l01040"></a>01040 
<a name="l01041"></a>01041         CvMat *smoothing_factors;
<a name="l01042"></a>01042 
<a name="l01043"></a>01043         <span class="keyword">volatile</span> <span class="keywordtype">bool</span> inSwap;
<a name="l01044"></a>01044         <span class="keyword">volatile</span> <span class="keywordtype">bool</span> inRead;
<a name="l01045"></a>01045         <span class="keyword">volatile</span> <span class="keywordtype">int</span> turn;
<a name="l01046"></a>01046 
<a name="l01047"></a>01047         <a class="code" href="structVisageSDK_1_1TrackingData.html">TrackingData</a>* trackingData;
<a name="l01048"></a>01048 <span class="preprocessor">#if defined(IOS) || defined(ANDROID) || defined(MAC_OS_X)</span>
<a name="l01049"></a>01049 <span class="preprocessor"></span>    pthread_mutex_t mutex;
<a name="l01050"></a>01050 <span class="preprocessor">#endif</span>
<a name="l01051"></a>01051 <span class="preprocessor"></span>
<a name="l01052"></a>01052 <span class="preprocessor">#ifdef WIN32</span>
<a name="l01053"></a>01053 <span class="preprocessor"></span>        CRITICAL_SECTION trackingData_cs;
<a name="l01054"></a>01054 <span class="preprocessor">#endif</span>
<a name="l01055"></a>01055 <span class="preprocessor"></span>
<a name="l01056"></a>01056         <span class="keywordtype">string</span> bdts_data_path; <span class="comment">// path to the folder containing boosted decision trees</span>
<a name="l01057"></a>01057         VisageDetector* m_DetectorBDFS;
<a name="l01058"></a>01058 
<a name="l01059"></a>01059         <span class="keyword">static</span> <span class="keywordtype">void</span> detectInThread(<span class="keywordtype">void</span>* arg);
<a name="l01060"></a>01060         <span class="keyword">volatile</span> <span class="keywordtype">bool</span> inDetectorThread;
<a name="l01061"></a>01061         <span class="keyword">volatile</span> <span class="keywordtype">bool</span> stopDetectorThread;
<a name="l01062"></a>01062 
<a name="l01063"></a>01063         IplImage* detector_frame;
<a name="l01064"></a>01064         <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a>* detector_fp;
<a name="l01065"></a>01065         <span class="keyword">volatile</span> <span class="keywordtype">int</span> facialFeat;
<a name="l01066"></a>01066         <span class="keyword">volatile</span> <span class="keywordtype">int</span> detector_parts;
<a name="l01067"></a>01067         <span class="keyword">volatile</span> <span class="keywordtype">int</span> detect;
<a name="l01068"></a>01068         <span class="keyword">volatile</span> <span class="keywordtype">int</span> new_detector_frame;
<a name="l01069"></a>01069 
<a name="l01070"></a>01070         <span class="keywordtype">int</span> windowScaler;
<a name="l01071"></a>01071 
<a name="l01072"></a>01072 };
<a name="l01073"></a>01073 
<a name="l01074"></a>01074 }
<a name="l01075"></a>01075 <span class="preprocessor">#endif // __VisageTracker2_h__</span>
<a name="l01076"></a>01076 <span class="preprocessor"></span>
</pre></div></div><!-- contents -->


<hr class="footer"/><address class="footer"><small>
Generated on Mon May 26 2014 11:59:40 for visageSDK by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.7.6.1
</small></address>

</body>
</html>
