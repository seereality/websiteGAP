<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>visageSDK: VisageFeaturesDetector.h Source File</title>

<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css" />



</head>
<body>
<div id="top"><!-- do not remove this div! -->


<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  
  
  <td style="padding-left: 0.5em;">
   <div id="projectname">visageSDK
   
   </div>
   
  </td>
  
  
  
 </tr>
 </tbody>
</table>
</div>

<!-- Generated by Doxygen 1.7.6.1 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
    </ul>
  </div>
</div>
<div class="header">
  <div class="headertitle">
<div class="title">VisageFeaturesDetector.h</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 
<a name="l00002"></a>00002 <span class="preprocessor">#ifndef __VisageFeaturesDetector_h__</span>
<a name="l00003"></a>00003 <span class="preprocessor"></span><span class="preprocessor">#define __VisageFeaturesDetector_h__</span>
<a name="l00004"></a>00004 <span class="preprocessor"></span>
<a name="l00005"></a>00005 <span class="preprocessor">#ifdef VISAGE_STATIC</span>
<a name="l00006"></a>00006 <span class="preprocessor"></span><span class="preprocessor">        #define VISAGE_DECLSPEC</span>
<a name="l00007"></a>00007 <span class="preprocessor"></span><span class="preprocessor">#else</span>
<a name="l00008"></a>00008 <span class="preprocessor"></span>
<a name="l00009"></a>00009 <span class="preprocessor">        #ifdef VISAGE_EXPORTS</span>
<a name="l00010"></a>00010 <span class="preprocessor"></span><span class="preprocessor">                #define VISAGE_DECLSPEC __declspec(dllexport)</span>
<a name="l00011"></a>00011 <span class="preprocessor"></span><span class="preprocessor">        #else</span>
<a name="l00012"></a>00012 <span class="preprocessor"></span><span class="preprocessor">                #define VISAGE_DECLSPEC __declspec(dllimport)</span>
<a name="l00013"></a>00013 <span class="preprocessor"></span><span class="preprocessor">        #endif</span>
<a name="l00014"></a>00014 <span class="preprocessor"></span>
<a name="l00015"></a>00015 <span class="preprocessor">#endif</span>
<a name="l00016"></a>00016 <span class="preprocessor"></span>
<a name="l00017"></a>00017 
<a name="l00018"></a>00018 <span class="preprocessor">#include &lt;cstdlib&gt;</span>
<a name="l00019"></a>00019 <span class="preprocessor">#include &quot;VisageDetector.h&quot;</span>
<a name="l00020"></a>00020 <span class="preprocessor">#include &quot;FBFT/FBFT.h&quot;</span>
<a name="l00021"></a>00021 <span class="preprocessor">#include &quot;FaceData.h&quot;</span>
<a name="l00022"></a>00022 
<a name="l00023"></a>00023 <span class="keyword">using namespace </span>std;
<a name="l00024"></a>00024 
<a name="l00025"></a>00025 <span class="keyword">namespace </span>VisageSDK
<a name="l00026"></a>00026 {
<a name="l00027"></a>00027 
<a name="l00051"></a><a class="code" href="classVisageSDK_1_1VisageFeaturesDetector.html">00051</a> <span class="keyword">class </span>VISAGE_DECLSPEC <a class="code" href="classVisageSDK_1_1VisageFeaturesDetector.html" title="Faces and facial features detector implementation.">VisageFeaturesDetector</a>{
<a name="l00052"></a>00052 
<a name="l00053"></a>00053 <span class="keyword">public</span>:
<a name="l00054"></a>00054 
<a name="l00058"></a>00058         <a class="code" href="classVisageSDK_1_1VisageFeaturesDetector.html" title="Faces and facial features detector implementation.">VisageFeaturesDetector</a>();
<a name="l00059"></a>00059 
<a name="l00060"></a>00060 
<a name="l00063"></a>00063         ~<a class="code" href="classVisageSDK_1_1VisageFeaturesDetector.html" title="Faces and facial features detector implementation.">VisageFeaturesDetector</a>();
<a name="l00064"></a>00064 
<a name="l00065"></a>00065         <span class="comment">/* Initialise the feature detector. </span>
<a name="l00066"></a>00066 <span class="comment">        *</span>
<a name="l00067"></a>00067 <span class="comment">        * In order to initialise the feature detector, this function loads the generic Active Appearance %Model into memory. This model is needed for facial features detection. </span>
<a name="l00068"></a>00068 <span class="comment">        * The default model named &quot;genericModel&quot; is provided in the folder Samples/OpenGL/data/FaceDetector. Therefore, to initialise the feature detector</span>
<a name="l00069"></a>00069 <span class="comment">        * you may do something like:</span>
<a name="l00070"></a>00070 <span class="comment">        *</span>
<a name="l00071"></a>00071 <span class="comment">        *       std::string aamFileName(&quot;../../data/FaceDetector/genericModel&quot;);</span>
<a name="l00072"></a>00072 <span class="comment">        *       </span>
<a name="l00073"></a>00073 <span class="comment">        *       m_Detector-&gt;LoadStaticModel(&amp;aamFileName);</span>
<a name="l00074"></a>00074 <span class="comment">        *</span>
<a name="l00075"></a>00075 <span class="comment">        * It is best to see how it works in the sample project &lt;a href=&quot;../../../Samples/OpenGL/build/msvc90/FaceTracker/doc/html/index.html&quot;&gt;VisionExample&lt;/a&gt;.</span>
<a name="l00076"></a>00076 <span class="comment">        *</span>
<a name="l00077"></a>00077 <span class="comment">        * The model is actually comprised of two files: one containing the shape information</span>
<a name="l00078"></a>00078 <span class="comment">        * and another containing the appearance information.</span>
<a name="l00079"></a>00079 <span class="comment">        * The two files have extension .shape and .app respectively.</span>
<a name="l00080"></a>00080 <span class="comment">        * The filename passed as parameter should have no extension. If the files are not in the working directory</span>
<a name="l00081"></a>00081 <span class="comment">        * the full path must be given.</span>
<a name="l00082"></a>00082 <span class="comment">        * </span>
<a name="l00083"></a>00083 <span class="comment">        * </span>
<a name="l00084"></a>00084 <span class="comment">        * @param aamSFileName the name of appearance model files</span>
<a name="l00085"></a>00085 <span class="comment">        * @return true if successful</span>
<a name="l00086"></a>00086 <span class="comment">        */</span>
<a name="l00087"></a>00087         <span class="comment">//bool LoadStaticModel(const char* aamSFileName, bool show = false);</span>
<a name="l00088"></a>00088         
<a name="l00105"></a>00105         <span class="keywordtype">bool</span> Initialize(<span class="keyword">const</span> <span class="keywordtype">char</span>* path);
<a name="l00106"></a>00106 
<a name="l00107"></a>00107         <span class="comment">/*</span>
<a name="l00108"></a>00108 <span class="comment">        * Performs facial features detection from a still image containing a face.</span>
<a name="l00109"></a>00109 <span class="comment">        *  </span>
<a name="l00110"></a>00110 <span class="comment">        * The face in the picture should have neutral expression (i.e., facial muscles relaxed and lips closed)</span>
<a name="l00111"></a>00111 <span class="comment">        * and be facing the camera (not rotated). To achieve the best detection please provide a good quality picture, with diffuse</span>
<a name="l00112"></a>00112 <span class="comment">        * lighting conditions and where the head is in the middle of the image, taking not too much of the image area (i.e., less than 50%).</span>
<a name="l00113"></a>00113 <span class="comment">        * </span>
<a name="l00114"></a>00114 <span class="comment">        * The algorithm detects the face and its features. The result are the coordinates of facial feature points, e.g. chin tip, nose tip, lip corners etc. Coordinates are normalised, so that</span>
<a name="l00115"></a>00115 <span class="comment">        * the upper left corner of the image has coordinates 0,0 and the lower right corner has coordinates 1,1. </span>
<a name="l00116"></a>00116 <span class="comment">        *</span>
<a name="l00117"></a>00117 <span class="comment">        * The feature points are identified</span>
<a name="l00118"></a>00118 <span class="comment">        * according to the MPEG-4 standard, so each feature point is identified by its group and index. For example, the tip of the chin</span>
<a name="l00119"></a>00119 <span class="comment">        * belongs to group 2 and its index is 1, so this point is identified as point 2.1. The identification of all MPEG-4 feature points is</span>
<a name="l00120"></a>00120 <span class="comment">        * illustrated in Figure 2 on Page 8 of the &lt;a href=&quot;MPEG-4 FBA Overview.pdf&quot;&gt;MPEG-4 Face and Body Animation Introduction&lt;/a&gt;.</span>
<a name="l00121"></a>00121 <span class="comment">        *</span>
<a name="l00122"></a>00122 <span class="comment">        * Certain feature points, like the ones on the tongue and teeth, can not be detected so they are not returned</span>
<a name="l00123"></a>00123 <span class="comment">        * and their coordinates are always set to zero. These points are:</span>
<a name="l00124"></a>00124 <span class="comment">        * 3.5, 3.6, 6.1, 6.2, 6.3, 6.4, 7.1, 9.8, 9.9, 9.10, 9.11, 10.5, 10.6, 10.9, 10.10, 11.5, 11.6</span>
<a name="l00125"></a>00125 <span class="comment">        * Several other points are estimated, rather than accurately detected, due to their specific locations. Examples of such points</span>
<a name="l00126"></a>00126 <span class="comment">        * are 11.4 (usually hidden in the hair), ears (10.x) as well as cheeck points 5.1 - 5.4 which can not be precisely defined due to lack of</span>
<a name="l00127"></a>00127 <span class="comment">        * features on the cheek. Four additional points from FDP group 12 are also estimated: left and right temple (12.44, 12.45) and the points</span>
<a name="l00128"></a>00128 <span class="comment">        * on the hairline above the temple, left and right (12.46, 12.47).</span>
<a name="l00129"></a>00129 <span class="comment">        *</span>
<a name="l00130"></a>00130 <span class="comment">        * The resulting feature point coordinates are returned in form of an FDP object. This is a container clas used for storage of MPEG-4 feature points.</span>
<a name="l00131"></a>00131 <span class="comment">        * It provides functions to access each feature point by its group and index and to read its coordinates. Note that FDP can store 3D points but</span>
<a name="l00132"></a>00132 <span class="comment">        * here only the x and y coordinates of each point are used.</span>
<a name="l00133"></a>00133 <span class="comment">        * </span>
<a name="l00134"></a>00134 <span class="comment">        * If a face was found in the image the return value of the function will be 0. If the detection failed, e.g. if the image does not </span>
<a name="l00135"></a>00135 <span class="comment">        * contain a face, the function returns the value of -1, and the FDP object is not filled with any feature point coordinates.</span>
<a name="l00136"></a>00136 <span class="comment">        * </span>
<a name="l00137"></a>00137 <span class="comment">        * @param imageFileName pointer to the source image file name. The supported file formats are JPEG, PNG, BMP and PPM.</span>
<a name="l00138"></a>00138 <span class="comment">        * @param output pointer to the FDP object in which the results will be returned; this object must be constructed (e.g. FDP *f = new %FDP()).</span>
<a name="l00139"></a>00139 <span class="comment">        * @return code representing the result of the detection: </span>
<a name="l00140"></a>00140 <span class="comment">        * -1 face not found</span>
<a name="l00141"></a>00141 <span class="comment">        * 0 detection done</span>
<a name="l00142"></a>00142 <span class="comment">        *</span>
<a name="l00143"></a>00143 <span class="comment">        */</span>
<a name="l00144"></a>00144         <span class="keywordtype">int</span> detectFacialFeatures(<span class="keyword">const</span> <span class="keywordtype">char</span>* imageFileName, <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a>* output,  <span class="keywordtype">bool</span> show = <span class="keyword">false</span>);<span class="comment">//, double accuracy = 0.8);</span>
<a name="l00145"></a>00145 
<a name="l00146"></a>00146         <span class="comment">/*</span>
<a name="l00147"></a>00147 <span class="comment">        * Performs facial features detection from a still image containing a face.</span>
<a name="l00148"></a>00148 <span class="comment">        * </span>
<a name="l00149"></a>00149 <span class="comment">        * The face in the picture should have neutral expression (i.e., facial muscles relaxed and lips closed)</span>
<a name="l00150"></a>00150 <span class="comment">        * and be facing the camera (not rotated). To achieve the best detection please provide a good quality picture, with diffuse</span>
<a name="l00151"></a>00151 <span class="comment">        * lighting conditions and where the head is in the middle of the image, taking not too much of the image area (i.e., less than 50%).</span>
<a name="l00152"></a>00152 <span class="comment">        * </span>
<a name="l00153"></a>00153 <span class="comment">        * The algorithm detects the face and its features. The result are the coordinates of facial feature points, e.g. chin tip, nose tip, lip corners etc. Coordinates are normalised, so that</span>
<a name="l00154"></a>00154 <span class="comment">        * the upper left corner of the image has coordinates 0,0 and the lower right corner has coordinates 1,1. </span>
<a name="l00155"></a>00155 <span class="comment">        *</span>
<a name="l00156"></a>00156 <span class="comment">        * The feature points are identified</span>
<a name="l00157"></a>00157 <span class="comment">        * according to the MPEG-4 standard, so each feature point is identified by its group and index. For example, the tip of the chin</span>
<a name="l00158"></a>00158 <span class="comment">        * belongs to group 2 and its index is 1, so this point is identified as point 2.1. The identification of all MPEG-4 feature points is</span>
<a name="l00159"></a>00159 <span class="comment">        * illustrated in Figure 2 on Page 8 of the &lt;a href=&quot;MPEG-4 FBA Overview.pdf&quot;&gt;MPEG-4 Face and Body Animation Introduction&lt;/a&gt;.</span>
<a name="l00160"></a>00160 <span class="comment">        *</span>
<a name="l00161"></a>00161 <span class="comment">        * Certain feature points, like the ones on the tongue and teeth, can not be detected so they are not returned</span>
<a name="l00162"></a>00162 <span class="comment">        * and their coordinates are always set to zero. These points are:</span>
<a name="l00163"></a>00163 <span class="comment">        * 3.5, 3.6, 6.1, 6.2, 6.3, 6.4, 7.1, 9.8, 9.9, 9.10, 9.11, 10.5, 10.6, 10.9, 10.10, 11.5, 11.6</span>
<a name="l00164"></a>00164 <span class="comment">        * Several other points are estimated, rather than accurately detected, due to their specific locations. Examples of such points</span>
<a name="l00165"></a>00165 <span class="comment">        * are 11.4 (usually hidden in the hair), ears (10.x) as well as cheeck points 5.1 - 5.4 which can not be precisely defined due to lack of</span>
<a name="l00166"></a>00166 <span class="comment">        * features on the cheek. Four additional points from FDP group 12 are also estimated: left and right temple (12.44, 12.45) and the points</span>
<a name="l00167"></a>00167 <span class="comment">        * on the hairline above the temple, left and right (12.46, 12.47).</span>
<a name="l00168"></a>00168 <span class="comment">        *</span>
<a name="l00169"></a>00169 <span class="comment">        * The resulting feature point coordinates are returned in form of an FDP object. This is a container clas used for storage of MPEG-4 feature points.</span>
<a name="l00170"></a>00170 <span class="comment">        * It provides functions to access each feature point by its group and index and to read its coordinates. Note that FDP can store 3D points but</span>
<a name="l00171"></a>00171 <span class="comment">        * here only the x and y coordinates of each point are used.</span>
<a name="l00172"></a>00172 <span class="comment">        * </span>
<a name="l00173"></a>00173 <span class="comment">        * If a face was found in the image the return value of the function will be 0. If the detection failed, e.g. if the image does not </span>
<a name="l00174"></a>00174 <span class="comment">        * contain a face, the function returns the value of -1, and the FDP object is not filled with any feature point coordinates.</span>
<a name="l00175"></a>00175 <span class="comment">        * </span>
<a name="l00176"></a>00176 <span class="comment">        * @param frame the input image.</span>
<a name="l00177"></a>00177 <span class="comment">        * @param output pointer to the FDP object in which the results will be returned; this object must be constructed (e.g. FDP *f = new %FDP()).</span>
<a name="l00178"></a>00178 <span class="comment">        * @return code representing the result of the detection: </span>
<a name="l00179"></a>00179 <span class="comment">        * -1 face not found</span>
<a name="l00180"></a>00180 <span class="comment">        * 0 detection done</span>
<a name="l00181"></a>00181 <span class="comment">        *</span>
<a name="l00182"></a>00182 <span class="comment">        */</span>
<a name="l00183"></a>00183         <span class="keywordtype">int</span> detectFacialFeatures(IplImage* frame, <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a>* output, <span class="keywordtype">bool</span> show = <span class="keyword">false</span>);<span class="comment">//, double accuracy = 0.8);</span>
<a name="l00184"></a>00184         
<a name="l00210"></a>00210         <span class="keywordtype">int</span> detectFacialFeatures(IplImage* frame, <a class="code" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results.">FaceData</a>* output, <span class="keywordtype">int</span> maxFaces = 1);
<a name="l00211"></a>00211 
<a name="l00236"></a>00236         <span class="keywordtype">int</span> detectFacialFeatures(<span class="keyword">const</span> <span class="keywordtype">char</span>* imageFileName, <a class="code" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results.">FaceData</a>* output, <span class="keywordtype">int</span> maxFaces = 1);
<a name="l00237"></a>00237 
<a name="l00238"></a>00238         <span class="comment">/*</span>
<a name="l00239"></a>00239 <span class="comment">        * Performs fast detection of main facial features from a still image containing a face.</span>
<a name="l00240"></a>00240 <span class="comment">        *</span>
<a name="l00241"></a>00241 <span class="comment">        * This function is similar to detectFacialFeatures() but with these important differences:</span>
<a name="l00242"></a>00242 <span class="comment">        * - it works much faster</span>
<a name="l00243"></a>00243 <span class="comment">        * - it supports some head rotation and facial expression, not just front-faces neutral faces</span>
<a name="l00244"></a>00244 <span class="comment">        * - it detects only eye centres, mouth corners and nose tip</span>
<a name="l00245"></a>00245 <span class="comment">        *</span>
<a name="l00246"></a>00246 <span class="comment">        * The result are the coordinates of facial feature points. Coordinates are normalised, so that</span>
<a name="l00247"></a>00247 <span class="comment">        * the upper left corner of the image has coordinates 0,0 and the lower right corner has coordinates 1,1. </span>
<a name="l00248"></a>00248 <span class="comment">        *</span>
<a name="l00249"></a>00249 <span class="comment">        * The feature points are identified</span>
<a name="l00250"></a>00250 <span class="comment">        * according to the MPEG-4 standard, so each feature point is identified by its group and index. For example, the tip of the chin</span>
<a name="l00251"></a>00251 <span class="comment">        * belongs to group 2 and its index is 1, so this point is identified as point 2.1. The identification of all MPEG-4 feature points is</span>
<a name="l00252"></a>00252 <span class="comment">        * illustrated in Figure 2 on Page 8 of the &lt;a href=&quot;MPEG-4 FBA Overview.pdf&quot;&gt;MPEG-4 Face and Body Animation Introduction&lt;/a&gt;.</span>
<a name="l00253"></a>00253 <span class="comment">        *</span>
<a name="l00254"></a>00254 <span class="comment">        * The resulting feature point coordinates are returned in form of an FDP object. This is a container clas used for storage of MPEG-4 feature points.</span>
<a name="l00255"></a>00255 <span class="comment">        * It provides functions to access each feature point by its group and index and to read its coordinates. Note that FDP can store 3D points but</span>
<a name="l00256"></a>00256 <span class="comment">        * here only the x and y coordinates of each point are used.</span>
<a name="l00257"></a>00257 <span class="comment">        *</span>
<a name="l00258"></a>00258 <span class="comment">        * The function tries to detect eye centres, mouth corners and the tip of the nose. The return value is a bit-wise indicator</span>
<a name="l00259"></a>00259 <span class="comment">        * of which features were succesfully detected. Starting from the least significant bit, the first bit indicates detection</span>
<a name="l00260"></a>00260 <span class="comment">        * of the face, second the eyes, third bit the mouth and fourth bit the nose. Thus return value 0 means that no face was detected, 1 means</span>
<a name="l00261"></a>00261 <span class="comment">        * the face was detectde but not any features, 2 means eyes were detected but not nose and mouth, 11 means nose and eyes were detected but not mouth, etc.</span>
<a name="l00262"></a>00262 <span class="comment">        * The value 15 means best possible detection when all features were detected.</span>
<a name="l00263"></a>00263 <span class="comment">        *</span>
<a name="l00264"></a>00264 <span class="comment">        * In case of nose and mouth, when the bit is set to 0 it means that these features are not detected and the corresponding feature points in the FDP object are not set. For the</span>
<a name="l00265"></a>00265 <span class="comment">        * eyes, the value of 0 means that the eyes positions were just estimated and not precisely detected. Eyes feature points in the FDP objects are always set.</span>
<a name="l00266"></a>00266 <span class="comment">        *</span>
<a name="l00267"></a>00267 <span class="comment">        * </span>
<a name="l00268"></a>00268 <span class="comment">        * @param frame the input image.</span>
<a name="l00269"></a>00269 <span class="comment">        * @param output pointer to the FDP object in which the results will be returned; this object must be constructed (e.g. FDP *f = new %FDP()).</span>
<a name="l00270"></a>00270 <span class="comment">        * @param parts flag that determines which facial features will be detected: EYES, NOSE, MOUTH, FACE</span>
<a name="l00271"></a>00271 <span class="comment">        * @return code representing the result of the detection, see above </span>
<a name="l00272"></a>00272 <span class="comment">        *</span>
<a name="l00273"></a>00273 <span class="comment">        * @see FDP, detectFacialFeatures()</span>
<a name="l00274"></a>00274 <span class="comment">        */</span>
<a name="l00275"></a>00275         <span class="keywordtype">int</span> detectMainFacialFeatures(IplImage* frame, <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a>* output, <span class="keywordtype">int</span> parts = VS_FACE);
<a name="l00276"></a>00276 
<a name="l00277"></a>00277         <span class="comment">/*</span>
<a name="l00278"></a>00278 <span class="comment">        * Performs fast detection of main facial features from a still image containing a face.</span>
<a name="l00279"></a>00279 <span class="comment">        *</span>
<a name="l00280"></a>00280 <span class="comment">        * This function is similar to detectFacialFeatures() but with these important differences:</span>
<a name="l00281"></a>00281 <span class="comment">        * - it works much faster</span>
<a name="l00282"></a>00282 <span class="comment">        * - it supports some head rotation and facial expression, not just front-faces neutral faces</span>
<a name="l00283"></a>00283 <span class="comment">        * - it detects only eye centres, mouth corners and nose tip</span>
<a name="l00284"></a>00284 <span class="comment">        *</span>
<a name="l00285"></a>00285 <span class="comment">        * The result are the coordinates of facial feature points. Coordinates are normalised, so that</span>
<a name="l00286"></a>00286 <span class="comment">        * the upper left corner of the image has coordinates 0,0 and the lower right corner has coordinates 1,1. </span>
<a name="l00287"></a>00287 <span class="comment">        *</span>
<a name="l00288"></a>00288 <span class="comment">        * The feature points are identified</span>
<a name="l00289"></a>00289 <span class="comment">        * according to the MPEG-4 standard, so each feature point is identified by its group and index. For example, the tip of the chin</span>
<a name="l00290"></a>00290 <span class="comment">        * belongs to group 2 and its index is 1, so this point is identified as point 2.1. The identification of all MPEG-4 feature points is</span>
<a name="l00291"></a>00291 <span class="comment">        * illustrated in Figure 2 on Page 8 of the &lt;a href=&quot;MPEG-4 FBA Overview.pdf&quot;&gt;MPEG-4 Face and Body Animation Introduction&lt;/a&gt;.</span>
<a name="l00292"></a>00292 <span class="comment">        *</span>
<a name="l00293"></a>00293 <span class="comment">        * The resulting feature point coordinates are returned in form of an FDP object. This is a container clas used for storage of MPEG-4 feature points.</span>
<a name="l00294"></a>00294 <span class="comment">        * It provides functions to access each feature point by its group and index and to read its coordinates. Note that FDP can store 3D points but</span>
<a name="l00295"></a>00295 <span class="comment">        * here only the x and y coordinates of each point are used.</span>
<a name="l00296"></a>00296 <span class="comment">        *</span>
<a name="l00297"></a>00297 <span class="comment">        * The function tries to detect eye centres, mouth corners and the tip of the nose. The return value is number of faces detected.</span>
<a name="l00298"></a>00298 <span class="comment">        * Additionaly function fills array of bitwise indicators of which features were succesfully detected on each detected face. Each element in filled array correspondes to one of detected faces. Starting from the least significant bit, the first bit in each element indicates detection</span>
<a name="l00299"></a>00299 <span class="comment">        * of the face, second the eyes, third bit the mouth and fourth bit the nose. Thus element value 1 means</span>
<a name="l00300"></a>00300 <span class="comment">        * the face was detected but not any features, 2 means eyes were detected but not nose and mouth, 11 means nose and eyes were detected but not mouth, etc. </span>
<a name="l00301"></a>00301 <span class="comment">        * The value 15 means best possible detection when all features were detected. If no faces were detected null pointer is returned.</span>
<a name="l00302"></a>00302 <span class="comment">        *</span>
<a name="l00303"></a>00303 <span class="comment">        * In case of nose and mouth, when the bit is set to 0 it means that these features are not detected and the corresponding feature points in the FDP object are not set. For the</span>
<a name="l00304"></a>00304 <span class="comment">        * eyes, the value of 0 means that the eyes positions were just estimated and not precisely detected. Eyes feature points in the FDP objects are always set.</span>
<a name="l00305"></a>00305 <span class="comment">        *</span>
<a name="l00306"></a>00306 <span class="comment">        * @param input the input image.</span>
<a name="l00307"></a>00307 <span class="comment">        * @param output pointer to the FDP object or array of FDP objects in which the results for each detected face will be returned; this object must be constructed (e.g. FDP *f = new %FDP()).</span>
<a name="l00308"></a>00308 <span class="comment">        * @param success array of bitwise indicators of which features where succesfully detected on each detected face, see above.</span>
<a name="l00309"></a>00309 <span class="comment">        * @param maxFaces maximum number of faces that can be detected</span>
<a name="l00310"></a>00310 <span class="comment">        * @param parts flag that determines which facial features will be detected: VS_EYES, VS_NOSE, VS_MOUTH, VS_FACE</span>
<a name="l00311"></a>00311 <span class="comment">        * @return represents the result of the detection as number of faces found</span>
<a name="l00312"></a>00312 <span class="comment">        *</span>
<a name="l00313"></a>00313 <span class="comment">        *</span>
<a name="l00314"></a>00314 <span class="comment">        * @see FDP, detectFacialFeatures()</span>
<a name="l00315"></a>00315 <span class="comment">        */</span>
<a name="l00316"></a>00316         <span class="keywordtype">int</span> detectMainFacialFeatures(IplImage* frame, <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a>* output, <span class="keywordtype">int</span>* success, <span class="keywordtype">int</span> maxFaces, <span class="keywordtype">int</span> parts);
<a name="l00317"></a>00317     
<a name="l00318"></a>00318         <span class="comment">/*</span>
<a name="l00319"></a>00319 <span class="comment">        * Draws the previously detected feature points on top of the provided image. </span>
<a name="l00320"></a>00320 <span class="comment">        * The image format is IplImage, provided by the Intel&#39;s OpenCV libraries.</span>
<a name="l00321"></a>00321 <span class="comment">        * </span>
<a name="l00322"></a>00322 <span class="comment">        * @param img the picture where the FDPs are to be drawn</span>
<a name="l00323"></a>00323 <span class="comment">        * @deprecated Will be removed in future release</span>
<a name="l00324"></a>00324 <span class="comment">        */</span>
<a name="l00325"></a>00325         <span class="keywordtype">void</span> DrawFDPs(IplImage* img);
<a name="l00326"></a>00326         
<a name="l00333"></a>00333         <span class="keywordtype">void</span> drawResults(IplImage* img);
<a name="l00334"></a>00334 
<a name="l00335"></a>00335         <span class="comment">//appearance model &quot;static&quot; used for facial features detection in still images</span>
<a name="l00336"></a>00336         <span class="comment">//StaticModel* aamS;</span>
<a name="l00337"></a>00337 
<a name="l00338"></a>00338         <span class="keywordtype">bool</span> initialised;
<a name="l00339"></a>00339 
<a name="l00340"></a>00340 <span class="keyword">private</span>:
<a name="l00341"></a>00341 
<a name="l00342"></a>00342         <a class="code" href="classVisageSDK_1_1VisageFeaturesDetector.html" title="Faces and facial features detector implementation.">VisageFeaturesDetector</a>(<span class="keyword">const</span> <span class="keywordtype">char</span> *dataPath);
<a name="l00343"></a>00343 
<a name="l00344"></a>00344         <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a>* fdps;
<a name="l00345"></a>00345         <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a>* featurePoints2D;
<a name="l00346"></a>00346 
<a name="l00347"></a>00347         <span class="keywordtype">void</span> calculateFDP(<a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a>* f, <span class="keywordtype">int</span> w, <span class="keywordtype">int</span> h, CvMat* vert, <span class="keywordtype">bool</span> _3D);
<a name="l00348"></a>00348         <span class="keywordtype">void</span> setFDPIndices(<a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a>* f);
<a name="l00349"></a>00349 
<a name="l00350"></a>00350         <span class="keywordtype">bool</span> fitModelToFace(<a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a> *input, <a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a>* output, IplImage *frame);
<a name="l00351"></a>00351         <span class="keywordtype">bool</span> fitModelToFace(<a class="code" href="classVisageSDK_1_1FDP.html" title="Feature points of a face.">FDP</a>* input, <a class="code" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results.">FaceData</a>* output, IplImage * frame);
<a name="l00352"></a>00352 
<a name="l00353"></a>00353         VisageDetector* detector;
<a name="l00354"></a>00354         FBFT* fbft;
<a name="l00355"></a>00355         <span class="keywordtype">char</span>* cfg;
<a name="l00356"></a>00356 
<a name="l00357"></a>00357         <a class="code" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results.">FaceData</a>* data;
<a name="l00358"></a>00358         <span class="keywordtype">int</span> faces;
<a name="l00359"></a>00359         
<a name="l00360"></a>00360         <span class="keywordtype">void</span> drawLines(IplImage* img, <span class="keywordtype">int</span>* points, <span class="keywordtype">int</span> num, <span class="keywordtype">int</span> r, <span class="keywordtype">int</span> g, <span class="keywordtype">int</span> b);
<a name="l00361"></a>00361         <span class="keywordtype">void</span> drawLineLoop(IplImage* img, <span class="keywordtype">int</span>* points, <span class="keywordtype">int</span> num, <span class="keywordtype">int</span> r, <span class="keywordtype">int</span> g, <span class="keywordtype">int</span> b);
<a name="l00362"></a>00362         <span class="keywordtype">void</span> drawPoints2D(IplImage* img, <span class="keywordtype">int</span>* points, <span class="keywordtype">int</span> num, <span class="keywordtype">int</span> r, <span class="keywordtype">int</span> g, <span class="keywordtype">int</span> b);
<a name="l00363"></a>00363 
<a name="l00364"></a>00364 };
<a name="l00365"></a>00365 
<a name="l00366"></a>00366 }
<a name="l00367"></a>00367 <span class="preprocessor">#endif // __VisageFeaturesDetector_h__</span>
<a name="l00368"></a>00368 <span class="preprocessor"></span>
</pre></div></div><!-- contents -->


<hr class="footer"/><address class="footer"><small>
Generated on Mon May 26 2014 11:59:40 for visageSDK by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.7.6.1
</small></address>

</body>
</html>
